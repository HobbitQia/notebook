# Paper

!!! Abstract
    这里用来放读论文的笔记，写的不好还请见谅>_<|||

<!-- ??? Note "TODO"
    - 重构页面，对论文分类
    - T-MAC + BitNet 系列
    - CoT
    - InstructGPT
    - 量化系列（Atom、QuaRot）
    - 投机解码 -->

* [BiS-KM: Enabling Any-Precision K-Means on FPGAs](BiS-KM.md)
* [ZeRO: Memory Optimizations Toward Training Trillion Parameter Models](ZeRO.md)
* [Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism](Megatron-LM.md)
* [GPipe: Efficient Training of Giant Neural Networks using Pipeline Parallelism](GPipe.md)
* [Mixed Precision Training](mixed_precision.md)
* [FAST: DNN Training Under Variable Precision Block Floating Point with Stochastic Rounding](FAST.md)
* [Softmax Acceleration with Adaptive Numeric Format for both Training and Inference](softmax.md)
* [Efficient Memory Management for Large Language Model Serving with PagedAttention](PagedAttention.md)
* [VecPAC: A Vectorizable and Precision-Aware CGRA](VecPAC.md)
* [NN-LUT: Neural Approximation of Non-Linear Operations for Efficient Transformer Inference](NN-LUT.md)
* [ChatEDA: A Large Language Model Powered Autonomous Agent for EDA](ChatEDA.md)
* [Improving Language Understanding by Generative Pre-Training](GPT-1.md)
* [Language Models are Unsupervised Multitask Learners](GPT-2.md)
* [Language Models are Few-Shot Learners](GPT-3.md)
* [APEX: A Framework for Automated Processing Element Design Space Exploration using Frequent Subgraph Analysis](APEX.md)
* [QServe: W4A8KV4 Quantization and System Co-design for Efficient LLM Serving](QServe.md)
* [Learning Transferable Visual Models From Natural Language Supervision](CLIP.md)
* [LLM2Vec: Large Language Models Are Secretly Powerful Text Encoders](LLM2Vec.md)
* [Diffusion + RL](T2I_RL.md)
* [SEER: Super-Optimization Explorer for High-Level Synthesis using E-graph Rewriting](Seer.md)