<!DOCTYPE html>
<html class="no-js" lang="zh">
<head>
<meta charset="utf-8"/>
<meta content="width=device-width,initial-scale=1" name="viewport"/>
<meta content="HobbitQia的笔记本" name="description"/>
<link href="https://note.hobbitqia.cc/TinyML/llm/" rel="canonical"/>
<link href="../quantization/" rel="prev"/>
<link href="../finetune/" rel="next"/>
<link href="../../log.ico" rel="icon"/>
<meta content="mkdocs-1.6.1, mkdocs-material-9.6.23" name="generator"/>
<title>Transformer &amp; LLM - HobbitQia的笔记本</title>
<link href="../../assets/stylesheets/main.84d31ad4.min.css" rel="stylesheet"/>
<link href="../../assets/stylesheets/palette.06af60db.min.css" rel="stylesheet"/>
<link crossorigin="" href="https://fonts.gstatic.com" rel="preconnect"/>
<link href="https://fonts.googleapis.com/css?family=LXGW+WenKai+Screen:300,300i,400,400i,700,700i%7CJetBrains+Mono:400,400i,700,700i&amp;display=fallback" rel="stylesheet"/>
<style>:root{--md-text-font:"LXGW WenKai Screen";--md-code-font:"JetBrains Mono"}</style>
<link href="../../css/timeline.css" rel="stylesheet"/>
<link href="../../css/heti.css" rel="stylesheet"/>
<link href="https://gcore.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css" rel="stylesheet"/>
<link href="https://gcore.jsdelivr.net/npm/lxgw-wenkai-screen-webfont@1.1.0/style.css" rel="stylesheet"/>
<link href="https://gcore.jsdelivr.net/npm/lxgw-wenkai-webfont@1.1.0/style.css" rel="stylesheet"/>
<link href="../../css/custom.css" rel="stylesheet"/>
<link href="../../css/card.css" rel="stylesheet"/>
<link href="../../css/tasklist.css" rel="stylesheet"/>
<link href="../../css/flink.css" rel="stylesheet"/>
<link href="../../css/more_changelog.css" rel="stylesheet"/>
<script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
</head>
<body data-md-color-accent="brown" data-md-color-primary="brown" data-md-color-scheme="default" dir="ltr">
<input autocomplete="off" class="md-toggle" data-md-toggle="drawer" id="__drawer" type="checkbox"/>
<input autocomplete="off" class="md-toggle" data-md-toggle="search" id="__search" type="checkbox"/>
<label class="md-overlay" for="__drawer"></label>
<div data-md-component="skip">
<a class="md-skip" href="#transformer-and-llm">
          跳转至
        </a>
</div>
<div data-md-component="announce">
</div>
<header class="md-header" data-md-component="header">
<nav aria-label="页眉" class="md-header__inner md-grid">
<a aria-label="HobbitQia的笔记本" class="md-header__button md-logo" data-md-component="logo" href="../.." title="HobbitQia的笔记本">
<img alt="logo" src="../../log.ico"/>
</a>
<label class="md-header__button md-icon" for="__drawer">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"></path></svg>
</label>
<div class="md-header__title" data-md-component="header-title">
<div class="md-header__ellipsis">
<div class="md-header__topic">
<span class="md-ellipsis">
            HobbitQia的笔记本
          </span>
</div>
<div class="md-header__topic" data-md-component="header-topic">
<span class="md-ellipsis">
            
              Transformer &amp; LLM
            
          </span>
</div>
</div>
</div>
<form class="md-header__option" data-md-component="palette">
<input aria-label="Switch to dark mode" class="md-option" data-md-color-accent="brown" data-md-color-media="(prefers-color-scheme: light)" data-md-color-primary="brown" data-md-color-scheme="default" id="__palette_0" name="__palette" type="radio"/>
<label class="md-header__button md-icon" for="__palette_1" hidden="" title="Switch to dark mode">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M12 7a5 5 0 0 1 5 5 5 5 0 0 1-5 5 5 5 0 0 1-5-5 5 5 0 0 1 5-5m0 2a3 3 0 0 0-3 3 3 3 0 0 0 3 3 3 3 0 0 0 3-3 3 3 0 0 0-3-3m0-7 2.39 3.42C13.65 5.15 12.84 5 12 5s-1.65.15-2.39.42zM3.34 7l4.16-.35A7.2 7.2 0 0 0 5.94 8.5c-.44.74-.69 1.5-.83 2.29zm.02 10 1.76-3.77a7.131 7.131 0 0 0 2.38 4.14zM20.65 7l-1.77 3.79a7.02 7.02 0 0 0-2.38-4.15zm-.01 10-4.14.36c.59-.51 1.12-1.14 1.54-1.86.42-.73.69-1.5.83-2.29zM12 22l-2.41-3.44c.74.27 1.55.44 2.41.44.82 0 1.63-.17 2.37-.44z"></path></svg>
</label>
<input aria-label="Switch to light mode" class="md-option" data-md-color-accent="indigo" data-md-color-media="(prefers-color-scheme: dark)" data-md-color-primary="indigo" data-md-color-scheme="slate" id="__palette_1" name="__palette" type="radio"/>
<label class="md-header__button md-icon" for="__palette_0" hidden="" title="Switch to light mode">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="m17.75 4.09-2.53 1.94.91 3.06-2.63-1.81-2.63 1.81.91-3.06-2.53-1.94L12.44 4l1.06-3 1.06 3zm3.5 6.91-1.64 1.25.59 1.98-1.7-1.17-1.7 1.17.59-1.98L15.75 11l2.06-.05L18.5 9l.69 1.95zm-2.28 4.95c.83-.08 1.72 1.1 1.19 1.85-.32.45-.66.87-1.08 1.27C15.17 23 8.84 23 4.94 19.07c-3.91-3.9-3.91-10.24 0-14.14.4-.4.82-.76 1.27-1.08.75-.53 1.93.36 1.85 1.19-.27 2.86.69 5.83 2.89 8.02a9.96 9.96 0 0 0 8.02 2.89m-1.64 2.02a12.08 12.08 0 0 1-7.8-3.47c-2.17-2.19-3.33-5-3.49-7.82-2.81 3.14-2.7 7.96.31 10.98 3.02 3.01 7.84 3.12 10.98.31"></path></svg>
</label>
</form>
<script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
<label class="md-header__button md-icon" for="__search">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"></path></svg>
</label>
<div class="md-search" data-md-component="search" role="dialog">
<label class="md-search__overlay" for="__search"></label>
<div class="md-search__inner" role="search">
<form class="md-search__form" name="search">
<input aria-label="搜索" autocapitalize="off" autocomplete="off" autocorrect="off" class="md-search__input" data-md-component="search-query" name="query" placeholder="搜索" required="" spellcheck="false" type="text"/>
<label class="md-search__icon md-icon" for="__search">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"></path></svg>
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"></path></svg>
</label>
<nav aria-label="查找" class="md-search__options">
<button aria-label="清空当前内容" class="md-search__icon md-icon" tabindex="-1" title="清空当前内容" type="reset">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"></path></svg>
</button>
</nav>
</form>
<div class="md-search__output">
<div class="md-search__scrollwrap" data-md-scrollfix="" tabindex="0">
<div class="md-search-result" data-md-component="search-result">
<div class="md-search-result__meta">
            正在初始化搜索引擎
          </div>
<ol class="md-search-result__list" role="presentation"></ol>
</div>
</div>
</div>
</div>
</div>
<div class="md-header__source">
<a class="md-source" data-md-component="source" href="https://github.com/HobbitQia/notebook/" title="前往仓库">
<div class="md-source__icon md-icon">
<svg viewbox="0 0 448 512" xmlns="http://www.w3.org/2000/svg"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"></path></svg>
</div>
<div class="md-source__repository">
    HobbitQia/notebook
  </div>
</a>
</div>
</nav>
</header>
<div class="md-container" data-md-component="container">
<nav aria-label="标签" class="md-tabs" data-md-component="tabs">
<div class="md-grid">
<ul class="md-tabs__list">
<li class="md-tabs__item">
<a class="md-tabs__link" href="../..">
          
  
  
    
  
  Home

        </a>
</li>
<li class="md-tabs__item">
<a class="md-tabs__link" href="../../ds/">
          
  
  
    
  
  Computer Science

        </a>
</li>
<li class="md-tabs__item">
<a class="md-tabs__link" href="../../ICS/">
          
  
  
    
  
  System

        </a>
</li>
<li class="md-tabs__item md-tabs__item--active">
<a class="md-tabs__link" href="../../DL/">
          
  
  
    
  
  AI

        </a>
</li>
<li class="md-tabs__item">
<a class="md-tabs__link" href="../../EDA/">
          
  
  
    
  
  EDA

        </a>
</li>
<li class="md-tabs__item">
<a class="md-tabs__link" href="../../Mathematics/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E2%85%A1%28H%29/Rings/">
          
  
  
    
  
  Mathematics

        </a>
</li>
<li class="md-tabs__item">
<a class="md-tabs__link" href="../../Paper/">
          
  
  
    
  
  Papers

        </a>
</li>
<li class="md-tabs__item">
<a class="md-tabs__link" href="../../Misc/">
          
  
  
    
  
  Miscellaneous

        </a>
</li>
</ul>
</div>
</nav>
<main class="md-main" data-md-component="main">
<div class="md-main__inner md-grid">
<div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation">
<div class="md-sidebar__scrollwrap">
<div class="md-sidebar__inner">
<nav aria-label="导航栏" class="md-nav md-nav--primary md-nav--lifted" data-md-level="0">
<label class="md-nav__title" for="__drawer">
<a aria-label="HobbitQia的笔记本" class="md-nav__button md-logo" data-md-component="logo" href="../.." title="HobbitQia的笔记本">
<img alt="logo" src="../../log.ico"/>
</a>
    HobbitQia的笔记本
  </label>
<div class="md-nav__source">
<a class="md-source" data-md-component="source" href="https://github.com/HobbitQia/notebook/" title="前往仓库">
<div class="md-source__icon md-icon">
<svg viewbox="0 0 448 512" xmlns="http://www.w3.org/2000/svg"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"></path></svg>
</div>
<div class="md-source__repository">
    HobbitQia/notebook
  </div>
</a>
</div>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item md-nav__item--nested">
<input class="md-nav__toggle md-toggle" id="__nav_1" type="checkbox"/>
<div class="md-nav__link md-nav__container">
<a class="md-nav__link" href="../..">
<span class="md-ellipsis">
    Home
    
  </span>
</a>
<label class="md-nav__link" for="__nav_1" id="__nav_1_label" tabindex="0">
<span class="md-nav__icon md-icon"></span>
</label>
</div>
<nav aria-expanded="false" aria-labelledby="__nav_1_label" class="md-nav" data-md-level="1">
<label class="md-nav__title" for="__nav_1">
<span class="md-nav__icon md-icon"></span>
            Home
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../changelog/">
<span class="md-ellipsis">
    更新记录
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../link/">
<span class="md-ellipsis">
    友链
    
  </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--nested">
<input class="md-nav__toggle md-toggle" id="__nav_2" type="checkbox"/>
<label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="0">
<span class="md-ellipsis">
    Computer Science
    
  </span>
<span class="md-nav__icon md-icon"></span>
</label>
<nav aria-expanded="false" aria-labelledby="__nav_2_label" class="md-nav" data-md-level="1">
<label class="md-nav__title" for="__nav_2">
<span class="md-nav__icon md-icon"></span>
            Computer Science
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item md-nav__item--nested">
<input class="md-nav__toggle md-toggle" id="__nav_2_1" type="checkbox"/>
<div class="md-nav__link md-nav__container">
<a class="md-nav__link" href="../../ds/">
<span class="md-ellipsis">
    数据结构与算法
    
  </span>
</a>
<label class="md-nav__link" for="__nav_2_1" id="__nav_2_1_label" tabindex="0">
<span class="md-nav__icon md-icon"></span>
</label>
</div>
<nav aria-expanded="false" aria-labelledby="__nav_2_1_label" class="md-nav" data-md-level="2">
<label class="md-nav__title" for="__nav_2_1">
<span class="md-nav__icon md-icon"></span>
            数据结构与算法
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../ds/algorithm/">
<span class="md-ellipsis">
    算法分析
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../ds/tree/">
<span class="md-ellipsis">
    树
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../ds/heap/">
<span class="md-ellipsis">
    堆
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../ds/set/">
<span class="md-ellipsis">
    并查集
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../ds/graph/">
<span class="md-ellipsis">
    图论
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../ds/sort/">
<span class="md-ellipsis">
    排序
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../ds/hash/">
<span class="md-ellipsis">
    散列
    
  </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--nested">
<input class="md-nav__toggle md-toggle" id="__nav_2_2" type="checkbox"/>
<div class="md-nav__link md-nav__container">
<a class="md-nav__link" href="../../ADS/">
<span class="md-ellipsis">
    高级数据结构与算法分析
    
  </span>
</a>
</div>
<nav aria-expanded="false" aria-labelledby="__nav_2_2_label" class="md-nav" data-md-level="2">
<label class="md-nav__title" for="__nav_2_2">
<span class="md-nav__icon md-icon"></span>
            高级数据结构与算法分析
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--nested">
<input class="md-nav__toggle md-toggle" id="__nav_2_3" type="checkbox"/>
<div class="md-nav__link md-nav__container">
<a class="md-nav__link" href="../../dip/">
<span class="md-ellipsis">
    图像信息处理
    
  </span>
</a>
<label class="md-nav__link" for="__nav_2_3" id="__nav_2_3_label" tabindex="0">
<span class="md-nav__icon md-icon"></span>
</label>
</div>
<nav aria-expanded="false" aria-labelledby="__nav_2_3_label" class="md-nav" data-md-level="2">
<label class="md-nav__title" for="__nav_2_3">
<span class="md-nav__icon md-icon"></span>
            图像信息处理
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../dip/dip1/">
<span class="md-ellipsis">
    图像信息处理介绍
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../dip/dip2/">
<span class="md-ellipsis">
    二值图像和形态学
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../dip/dip3/">
<span class="md-ellipsis">
    图像灰度变换与直方图
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../dip/dip5/">
<span class="md-ellipsis">
    几何变换
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../dip/dip6/">
<span class="md-ellipsis">
    卷积与滤波
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../dip/dip7/">
<span class="md-ellipsis">
    双边滤波的加速
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../dip/dip8/">
<span class="md-ellipsis">
    引导滤波
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../dip/dip9/">
<span class="md-ellipsis">
    稀疏范数滤波
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../dip/dip10/">
<span class="md-ellipsis">
    傅里叶变换
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../dip/dip11/">
<span class="md-ellipsis">
    图像特征检测和提取
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../dip/dip12/">
<span class="md-ellipsis">
    深度学习
    
  </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--nested">
<input class="md-nav__toggle md-toggle" id="__nav_2_4" type="checkbox"/>
<div class="md-nav__link md-nav__container">
<a class="md-nav__link" href="../../OOP/">
<span class="md-ellipsis">
    面向对象程序设计
    
  </span>
</a>
<label class="md-nav__link" for="__nav_2_4" id="__nav_2_4_label" tabindex="0">
<span class="md-nav__icon md-icon"></span>
</label>
</div>
<nav aria-expanded="false" aria-labelledby="__nav_2_4_label" class="md-nav" data-md-level="2">
<label class="md-nav__title" for="__nav_2_4">
<span class="md-nav__icon md-icon"></span>
            面向对象程序设计
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../OOP/oop1/">
<span class="md-ellipsis">
    Introduction
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../OOP/oop2/">
<span class="md-ellipsis">
    Class
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../OOP/oop3/">
<span class="md-ellipsis">
    Container
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../OOP/oop4/">
<span class="md-ellipsis">
    Function
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../OOP/oop5/">
<span class="md-ellipsis">
    Constant and Static
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../OOP/oop6/">
<span class="md-ellipsis">
    Inheritance
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../OOP/oop7/">
<span class="md-ellipsis">
    Polymorphism
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../OOP/oop8/">
<span class="md-ellipsis">
    Copy Ctor
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../OOP/oop9/">
<span class="md-ellipsis">
    Overloaded Operators
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../OOP/oop10/">
<span class="md-ellipsis">
    Templates
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../OOP/oop11/">
<span class="md-ellipsis">
    Exception
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../OOP/oop12/">
<span class="md-ellipsis">
    Smart Pointers
    
  </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--nested">
<input class="md-nav__toggle md-toggle" id="__nav_2_5" type="checkbox"/>
<div class="md-nav__link md-nav__container">
<a class="md-nav__link" href="../../Quan/">
<span class="md-ellipsis">
    量子计算理论与软件系统
    
  </span>
</a>
<label class="md-nav__link" for="__nav_2_5" id="__nav_2_5_label" tabindex="0">
<span class="md-nav__icon md-icon"></span>
</label>
</div>
<nav aria-expanded="false" aria-labelledby="__nav_2_5_label" class="md-nav" data-md-level="2">
<label class="md-nav__title" for="__nav_2_5">
<span class="md-nav__icon md-icon"></span>
            量子计算理论与软件系统
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../Quan/chap1/">
<span class="md-ellipsis">
    量子态与量子门
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../Quan/chap2/">
<span class="md-ellipsis">
    量子测量
    
  </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--nested">
<input class="md-nav__toggle md-toggle" id="__nav_2_6" type="checkbox"/>
<div class="md-nav__link md-nav__container">
<a class="md-nav__link" href="../../TCS/">
<span class="md-ellipsis">
    计算理论
    
  </span>
</a>
</div>
<nav aria-expanded="false" aria-labelledby="__nav_2_6_label" class="md-nav" data-md-level="2">
<label class="md-nav__title" for="__nav_2_6">
<span class="md-nav__icon md-icon"></span>
            计算理论
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--nested">
<input class="md-nav__toggle md-toggle" id="__nav_2_7" type="checkbox"/>
<div class="md-nav__link md-nav__container">
<a class="md-nav__link" href="../../AOR/">
<span class="md-ellipsis">
    应用运筹学基础
    
  </span>
</a>
</div>
<nav aria-expanded="false" aria-labelledby="__nav_2_7_label" class="md-nav" data-md-level="2">
<label class="md-nav__title" for="__nav_2_7">
<span class="md-nav__icon md-icon"></span>
            应用运筹学基础
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
</ul>
</nav>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--nested">
<input class="md-nav__toggle md-toggle" id="__nav_3" type="checkbox"/>
<label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="0">
<span class="md-ellipsis">
    System
    
  </span>
<span class="md-nav__icon md-icon"></span>
</label>
<nav aria-expanded="false" aria-labelledby="__nav_3_label" class="md-nav" data-md-level="1">
<label class="md-nav__title" for="__nav_3">
<span class="md-nav__icon md-icon"></span>
            System
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item md-nav__item--nested">
<input class="md-nav__toggle md-toggle" id="__nav_3_1" type="checkbox"/>
<div class="md-nav__link md-nav__container">
<a class="md-nav__link" href="../../ICS/">
<span class="md-ellipsis">
    计算机系统概论
    
  </span>
</a>
<label class="md-nav__link" for="__nav_3_1" id="__nav_3_1_label" tabindex="0">
<span class="md-nav__icon md-icon"></span>
</label>
</div>
<nav aria-expanded="false" aria-labelledby="__nav_3_1_label" class="md-nav" data-md-level="2">
<label class="md-nav__title" for="__nav_3_1">
<span class="md-nav__icon md-icon"></span>
            计算机系统概论
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../ICS/ICS-1/">
<span class="md-ellipsis">
    Introduction
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../ICS/ICS-2/">
<span class="md-ellipsis">
    Bits, Data Types and Operations
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../ICS/ICS-3/">
<span class="md-ellipsis">
    Digital Logic Structures
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../ICS/ICS-4/">
<span class="md-ellipsis">
    The von Neumann Model
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../ICS/ICS-5/">
<span class="md-ellipsis">
    LC-3
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../ICS/ICS-6/">
<span class="md-ellipsis">
    Programming
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../ICS/ICS-7/">
<span class="md-ellipsis">
    Assembly Language
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../ICS/ICS-8/">
<span class="md-ellipsis">
    Data Structures
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../ICS/ICS-9/">
<span class="md-ellipsis">
    I/0
    
  </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--nested">
<input class="md-nav__toggle md-toggle" id="__nav_3_2" type="checkbox"/>
<label class="md-nav__link" for="__nav_3_2" id="__nav_3_2_label" tabindex="0">
<span class="md-ellipsis">
    CSAPP
    
  </span>
<span class="md-nav__icon md-icon"></span>
</label>
<nav aria-expanded="false" aria-labelledby="__nav_3_2_label" class="md-nav" data-md-level="2">
<label class="md-nav__title" for="__nav_3_2">
<span class="md-nav__icon md-icon"></span>
            CSAPP
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../CSAPP/5/">
<span class="md-ellipsis">
    优化程序性能
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../CSAPP/6/">
<span class="md-ellipsis">
    存储器层次结构
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../CSAPP/7/">
<span class="md-ellipsis">
    链接
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../CSAPP/8/">
<span class="md-ellipsis">
    异常控制流
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../CSAPP/9/">
<span class="md-ellipsis">
    虚拟内存
    
  </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--nested">
<input class="md-nav__toggle md-toggle" id="__nav_3_3" type="checkbox"/>
<div class="md-nav__link md-nav__container">
<a class="md-nav__link" href="../../Logic/">
<span class="md-ellipsis">
    计算机逻辑设计基础
    
  </span>
</a>
<label class="md-nav__link" for="__nav_3_3" id="__nav_3_3_label" tabindex="0">
<span class="md-nav__icon md-icon"></span>
</label>
</div>
<nav aria-expanded="false" aria-labelledby="__nav_3_3_label" class="md-nav" data-md-level="2">
<label class="md-nav__title" for="__nav_3_3">
<span class="md-nav__icon md-icon"></span>
            计算机逻辑设计基础
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../Logic/logic01/">
<span class="md-ellipsis">
    数字系统和信息
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../Logic/logic02/">
<span class="md-ellipsis">
    组合逻辑电路
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../Logic/logic03/">
<span class="md-ellipsis">
    组合逻辑电路设计
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../Logic/logic04/">
<span class="md-ellipsis">
    时序逻辑电路
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../Logic/logic06/">
<span class="md-ellipsis">
    寄存器与寄存器传输
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../Logic/logic05/">
<span class="md-ellipsis">
    数字硬件设计
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../Logic/logic07/">
<span class="md-ellipsis">
    内存基础
    
  </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--nested">
<input class="md-nav__toggle md-toggle" id="__nav_3_4" type="checkbox"/>
<div class="md-nav__link md-nav__container">
<a class="md-nav__link" href="../../DB/">
<span class="md-ellipsis">
    数据库系统
    
  </span>
</a>
<label class="md-nav__link" for="__nav_3_4" id="__nav_3_4_label" tabindex="0">
<span class="md-nav__icon md-icon"></span>
</label>
</div>
<nav aria-expanded="false" aria-labelledby="__nav_3_4_label" class="md-nav" data-md-level="2">
<label class="md-nav__title" for="__nav_3_4">
<span class="md-nav__icon md-icon"></span>
            数据库系统
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../DB/db1/">
<span class="md-ellipsis">
    数据库介绍
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../DB/db2/">
<span class="md-ellipsis">
    关系模型
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../DB/db3/">
<span class="md-ellipsis">
    SQL 语言介绍
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../DB/db4/">
<span class="md-ellipsis">
    中级 SQL
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../DB/db5/">
<span class="md-ellipsis">
    高级 SQL
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../DB/db6/">
<span class="md-ellipsis">
    实体-关系模型
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../DB/db7/">
<span class="md-ellipsis">
    关系数据库设计
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../DB/db8/">
<span class="md-ellipsis">
    物理存储系统
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../DB/db9/">
<span class="md-ellipsis">
    数据存储结构
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../DB/db10/">
<span class="md-ellipsis">
    索引
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../DB/db11/">
<span class="md-ellipsis">
    查询处理
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../DB/db12/">
<span class="md-ellipsis">
    查询优化
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../DB/db13/">
<span class="md-ellipsis">
    事务
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../DB/db14/">
<span class="md-ellipsis">
    并发控制
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../DB/db15/">
<span class="md-ellipsis">
    故障恢复
    
  </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--nested">
<input class="md-nav__toggle md-toggle" id="__nav_3_5" type="checkbox"/>
<div class="md-nav__link md-nav__container">
<a class="md-nav__link" href="../../CO/">
<span class="md-ellipsis">
    计算机组成与设计
    
  </span>
</a>
<label class="md-nav__link" for="__nav_3_5" id="__nav_3_5_label" tabindex="0">
<span class="md-nav__icon md-icon"></span>
</label>
</div>
<nav aria-expanded="false" aria-labelledby="__nav_3_5_label" class="md-nav" data-md-level="2">
<label class="md-nav__title" for="__nav_3_5">
<span class="md-nav__icon md-icon"></span>
            计算机组成与设计
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../CO/co1/">
<span class="md-ellipsis">
    计算机概要与技术
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../CO/co3/">
<span class="md-ellipsis">
    计算机的算术运算
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../CO/co2/">
<span class="md-ellipsis">
    指令：计算机的语言
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../CO/co4/">
<span class="md-ellipsis">
    处理器
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../CO/co5/">
<span class="md-ellipsis">
    内存层次架构
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../CO/co6/">
<span class="md-ellipsis">
    存储和 IO
    
  </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--nested">
<input class="md-nav__toggle md-toggle" id="__nav_3_6" type="checkbox"/>
<div class="md-nav__link md-nav__container">
<a class="md-nav__link" href="../../CA/">
<span class="md-ellipsis">
    计算机体系结构
    
  </span>
</a>
<label class="md-nav__link" for="__nav_3_6" id="__nav_3_6_label" tabindex="0">
<span class="md-nav__icon md-icon"></span>
</label>
</div>
<nav aria-expanded="false" aria-labelledby="__nav_3_6_label" class="md-nav" data-md-level="2">
<label class="md-nav__title" for="__nav_3_6">
<span class="md-nav__icon md-icon"></span>
            计算机体系结构
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../CA/CA1/">
<span class="md-ellipsis">
    计算机设计基础
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../CA/CA2/">
<span class="md-ellipsis">
    流水线
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../CA/CA3/">
<span class="md-ellipsis">
    内存层次
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../CA/CA4/">
<span class="md-ellipsis">
    指令级并行
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../CA/CA5/">
<span class="md-ellipsis">
    DLP 和 TLP
    
  </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--nested">
<input class="md-nav__toggle md-toggle" id="__nav_3_7" type="checkbox"/>
<div class="md-nav__link md-nav__container">
<a class="md-nav__link" href="../../OS/">
<span class="md-ellipsis">
    操作系统原理与实践
    
  </span>
</a>
<label class="md-nav__link" for="__nav_3_7" id="__nav_3_7_label" tabindex="0">
<span class="md-nav__icon md-icon"></span>
</label>
</div>
<nav aria-expanded="false" aria-labelledby="__nav_3_7_label" class="md-nav" data-md-level="2">
<label class="md-nav__title" for="__nav_3_7">
<span class="md-nav__icon md-icon"></span>
            操作系统原理与实践
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../OS/chap01/">
<span class="md-ellipsis">
    OS 结构
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../OS/chap02/">
<span class="md-ellipsis">
    进程
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../OS/chap03/">
<span class="md-ellipsis">
    进程间通信
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../OS/chap04/">
<span class="md-ellipsis">
    线程
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../OS/chap05/">
<span class="md-ellipsis">
    调度
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../OS/chap06/">
<span class="md-ellipsis">
    同步
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../OS/chap07/">
<span class="md-ellipsis">
    死锁
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../OS/chap08/">
<span class="md-ellipsis">
    主存
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../OS/chap09/">
<span class="md-ellipsis">
    虚拟内存
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../OS/chap10/">
<span class="md-ellipsis">
    大容量存储
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../OS/chap11/">
<span class="md-ellipsis">
    I/O 系统
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../OS/chap12/">
<span class="md-ellipsis">
    文件系统接口
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../OS/chap13/">
<span class="md-ellipsis">
    文件系统实现
    
  </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--nested">
<input class="md-nav__toggle md-toggle" id="__nav_3_8" type="checkbox"/>
<div class="md-nav__link md-nav__container">
<a class="md-nav__link" href="../../Compiler/">
<span class="md-ellipsis">
    编译原理
    
  </span>
</a>
<label class="md-nav__link" for="__nav_3_8" id="__nav_3_8_label" tabindex="0">
<span class="md-nav__icon md-icon"></span>
</label>
</div>
<nav aria-expanded="false" aria-labelledby="__nav_3_8_label" class="md-nav" data-md-level="2">
<label class="md-nav__title" for="__nav_3_8">
<span class="md-nav__icon md-icon"></span>
            编译原理
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../Compiler/lec1/">
<span class="md-ellipsis">
    介绍
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../Compiler/lec2/">
<span class="md-ellipsis">
    词法分析
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../Compiler/lec3/">
<span class="md-ellipsis">
    语法分析
    
  </span>
</a>
</li>
</ul>
</nav>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
<input checked="" class="md-nav__toggle md-toggle" id="__nav_4" type="checkbox"/>
<label class="md-nav__link" for="__nav_4" id="__nav_4_label" tabindex="">
<span class="md-ellipsis">
    AI
    
  </span>
<span class="md-nav__icon md-icon"></span>
</label>
<nav aria-expanded="true" aria-labelledby="__nav_4_label" class="md-nav" data-md-level="1">
<label class="md-nav__title" for="__nav_4">
<span class="md-nav__icon md-icon"></span>
            AI
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item md-nav__item--nested">
<input class="md-nav__toggle md-toggle" id="__nav_4_1" type="checkbox"/>
<div class="md-nav__link md-nav__container">
<a class="md-nav__link" href="../../DL/">
<span class="md-ellipsis">
    Deep Learning
    
  </span>
</a>
<label class="md-nav__link" for="__nav_4_1" id="__nav_4_1_label" tabindex="0">
<span class="md-nav__icon md-icon"></span>
</label>
</div>
<nav aria-expanded="false" aria-labelledby="__nav_4_1_label" class="md-nav" data-md-level="2">
<label class="md-nav__title" for="__nav_4_1">
<span class="md-nav__icon md-icon"></span>
            Deep Learning
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../DL/lec01/">
<span class="md-ellipsis">
    图像分类
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../DL/lec02/">
<span class="md-ellipsis">
    线性分类器
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../DL/lec03/">
<span class="md-ellipsis">
    优化
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../DL/lec04/">
<span class="md-ellipsis">
    神经网络
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../DL/lec05/">
<span class="md-ellipsis">
    反向传播
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../DL/lec06/">
<span class="md-ellipsis">
    卷积神经网络
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../DL/lec07/">
<span class="md-ellipsis">
    CNN 架构
    
  </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--active md-nav__item--nested">
<input checked="" class="md-nav__toggle md-toggle" id="__nav_4_2" type="checkbox"/>
<div class="md-nav__link md-nav__container">
<a class="md-nav__link" href="../">
<span class="md-ellipsis">
    Efficient ML
    
  </span>
</a>
<label class="md-nav__link" for="__nav_4_2" id="__nav_4_2_label" tabindex="0">
<span class="md-nav__icon md-icon"></span>
</label>
</div>
<nav aria-expanded="true" aria-labelledby="__nav_4_2_label" class="md-nav" data-md-level="2">
<label class="md-nav__title" for="__nav_4_2">
<span class="md-nav__icon md-icon"></span>
            Efficient ML
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../pruning/">
<span class="md-ellipsis">
    剪枝与稀疏性
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../quantization/">
<span class="md-ellipsis">
    量化
    
  </span>
</a>
</li>
<li class="md-nav__item md-nav__item--active">
<input class="md-nav__toggle md-toggle" id="__toc" type="checkbox"/>
<label class="md-nav__link md-nav__link--active" for="__toc">
<span class="md-ellipsis">
    Transformer &amp; LLM
    
  </span>
<span class="md-nav__icon md-icon"></span>
</label>
<a class="md-nav__link md-nav__link--active" href="./">
<span class="md-ellipsis">
    Transformer &amp; LLM
    
  </span>
</a>
<nav aria-label="目录" class="md-nav md-nav--secondary">
<label class="md-nav__title" for="__toc">
<span class="md-nav__icon md-icon"></span>
      目录
    </label>
<ul class="md-nav__list" data-md-component="toc" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="#transformer-basics">
<span class="md-ellipsis">
      Transformer Basics
    </span>
</a>
<nav aria-label="Transformer Basics" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#revist-nlp-tasks">
<span class="md-ellipsis">
      Revist: NLP Tasks
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#transformer">
<span class="md-ellipsis">
      Transformer
    </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#transformer-design-variants">
<span class="md-ellipsis">
      Transformer Design Variants
    </span>
</a>
<nav aria-label="Transformer Design Variants" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#encoder-decoder">
<span class="md-ellipsis">
      Encoder &amp; Decoder
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#positional-encoding">
<span class="md-ellipsis">
      Positional Encoding
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#kv-cache-optimizations">
<span class="md-ellipsis">
      KV Cache Optimizations
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#improving-over-ffn">
<span class="md-ellipsis">
      Improving over FFN
    </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#large-language-models-llms">
<span class="md-ellipsis">
      Large language models (LLMs)
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#efficient-inference-algorithms-for-llms">
<span class="md-ellipsis">
      Efficient inference algorithms for LLMs
    </span>
</a>
<nav aria-label="Efficient inference algorithms for LLMs" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#quantization">
<span class="md-ellipsis">
      Quantization
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#pruningsparsity">
<span class="md-ellipsis">
      Pruning/Sparsity
    </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#efficient-inference-systems-for-llms">
<span class="md-ellipsis">
      Efficient inference systems for LLMs
    </span>
</a>
<nav aria-label="Efficient inference systems for LLMs" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#vllm-and-paged-attention">
<span class="md-ellipsis">
      vLLM and Paged Attention
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#streamingllm">
<span class="md-ellipsis">
      StreamingLLM
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#flashattention">
<span class="md-ellipsis">
      FlashAttention
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#speculative-decoding">
<span class="md-ellipsis">
      Speculative Decoding
    </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#efficient-fine-tuning-for-llms">
<span class="md-ellipsis">
      Efficient fine-tuning for LLMs
    </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../finetune/">
<span class="md-ellipsis">
    微调和提示工程
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../post-training/">
<span class="md-ellipsis">
    训练后 LLM
    
  </span>
</a>
</li>
</ul>
</nav>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--nested">
<input class="md-nav__toggle md-toggle" id="__nav_5" type="checkbox"/>
<div class="md-nav__link md-nav__container">
<a class="md-nav__link" href="../../EDA/">
<span class="md-ellipsis">
    EDA
    
  </span>
</a>
<label class="md-nav__link" for="__nav_5" id="__nav_5_label" tabindex="0">
<span class="md-nav__icon md-icon"></span>
</label>
</div>
<nav aria-expanded="false" aria-labelledby="__nav_5_label" class="md-nav" data-md-level="1">
<label class="md-nav__title" for="__nav_5">
<span class="md-nav__icon md-icon"></span>
            EDA
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item md-nav__item--nested">
<input class="md-nav__toggle md-toggle" id="__nav_5_2" type="checkbox"/>
<div class="md-nav__link md-nav__container">
<a class="md-nav__link" href="../../EDA/VLSI/">
<span class="md-ellipsis">
    数字集成电路设计
    
  </span>
</a>
<label class="md-nav__link" for="__nav_5_2" id="__nav_5_2_label" tabindex="0">
<span class="md-nav__icon md-icon"></span>
</label>
</div>
<nav aria-expanded="false" aria-labelledby="__nav_5_2_label" class="md-nav" data-md-level="2">
<label class="md-nav__title" for="__nav_5_2">
<span class="md-nav__icon md-icon"></span>
            数字集成电路设计
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../EDA/VLSI/lec01/">
<span class="md-ellipsis">
    介绍
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../EDA/VLSI/lec03/">
<span class="md-ellipsis">
    逻辑综合
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../EDA/VLSI/lec04/">
<span class="md-ellipsis">
    时序分析
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../EDA/VLSI/lec05/">
<span class="md-ellipsis">
    芯片物理设计
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../EDA/VLSI/lec06/">
<span class="md-ellipsis">
    布局
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../EDA/VLSI/lec07/">
<span class="md-ellipsis">
    时钟树综合
    
  </span>
</a>
</li>
</ul>
</nav>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--nested">
<input class="md-nav__toggle md-toggle" id="__nav_6" type="checkbox"/>
<label class="md-nav__link" for="__nav_6" id="__nav_6_label" tabindex="0">
<span class="md-ellipsis">
    Mathematics
    
  </span>
<span class="md-nav__icon md-icon"></span>
</label>
<nav aria-expanded="false" aria-labelledby="__nav_6_label" class="md-nav" data-md-level="1">
<label class="md-nav__title" for="__nav_6">
<span class="md-nav__icon md-icon"></span>
            Mathematics
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item md-nav__item--nested">
<input class="md-nav__toggle md-toggle" id="__nav_6_1" type="checkbox"/>
<label class="md-nav__link" for="__nav_6_1" id="__nav_6_1_label" tabindex="0">
<span class="md-ellipsis">
    线性代数
    
  </span>
<span class="md-nav__icon md-icon"></span>
</label>
<nav aria-expanded="false" aria-labelledby="__nav_6_1_label" class="md-nav" data-md-level="2">
<label class="md-nav__title" for="__nav_6_1">
<span class="md-nav__icon md-icon"></span>
            线性代数
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../Mathematics/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E2%85%A1%28H%29/Rings/">
<span class="md-ellipsis">
    线性代数Ⅱ(H)
    
  </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--nested">
<input class="md-nav__toggle md-toggle" id="__nav_6_2" type="checkbox"/>
<label class="md-nav__link" for="__nav_6_2" id="__nav_6_2_label" tabindex="0">
<span class="md-ellipsis">
    数据建模与分析
    
  </span>
<span class="md-nav__icon md-icon"></span>
</label>
<nav aria-expanded="false" aria-labelledby="__nav_6_2_label" class="md-nav" data-md-level="2">
<label class="md-nav__title" for="__nav_6_2">
<span class="md-nav__icon md-icon"></span>
            数据建模与分析
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../MLT/report/">
<span class="md-ellipsis">
    读书报告
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../MLT/mlt2/">
<span class="md-ellipsis">
    感知机
    
  </span>
</a>
</li>
</ul>
</nav>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--nested">
<input class="md-nav__toggle md-toggle" id="__nav_7" type="checkbox"/>
<div class="md-nav__link md-nav__container">
<a class="md-nav__link" href="../../Paper/">
<span class="md-ellipsis">
    Papers
    
  </span>
</a>
<label class="md-nav__link" for="__nav_7" id="__nav_7_label" tabindex="0">
<span class="md-nav__icon md-icon"></span>
</label>
</div>
<nav aria-expanded="false" aria-labelledby="__nav_7_label" class="md-nav" data-md-level="1">
<label class="md-nav__title" for="__nav_7">
<span class="md-nav__icon md-icon"></span>
            Papers
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item md-nav__item--nested">
<input class="md-nav__toggle md-toggle" id="__nav_7_2" type="checkbox"/>
<label class="md-nav__link" for="__nav_7_2" id="__nav_7_2_label" tabindex="0">
<span class="md-ellipsis">
    LLM Training
    
  </span>
<span class="md-nav__icon md-icon"></span>
</label>
<nav aria-expanded="false" aria-labelledby="__nav_7_2_label" class="md-nav" data-md-level="2">
<label class="md-nav__title" for="__nav_7_2">
<span class="md-nav__icon md-icon"></span>
            LLM Training
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../Paper/ZeRO/">
<span class="md-ellipsis">
    ZeRO
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../Paper/Megatron-LM/">
<span class="md-ellipsis">
    Megatron-LM
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../Paper/GPipe/">
<span class="md-ellipsis">
    GPipe
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../Paper/mixed_precision/">
<span class="md-ellipsis">
    混合精度训练
    
  </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--nested">
<input class="md-nav__toggle md-toggle" id="__nav_7_3" type="checkbox"/>
<label class="md-nav__link" for="__nav_7_3" id="__nav_7_3_label" tabindex="0">
<span class="md-ellipsis">
    LLM Inference
    
  </span>
<span class="md-nav__icon md-icon"></span>
</label>
<nav aria-expanded="false" aria-labelledby="__nav_7_3_label" class="md-nav" data-md-level="2">
<label class="md-nav__title" for="__nav_7_3">
<span class="md-nav__icon md-icon"></span>
            LLM Inference
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../Paper/PagedAttention/">
<span class="md-ellipsis">
    PagedAttention &amp; vLLM
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../Paper/QServe/">
<span class="md-ellipsis">
    QServe
    
  </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--nested">
<input class="md-nav__toggle md-toggle" id="__nav_7_4" type="checkbox"/>
<label class="md-nav__link" for="__nav_7_4" id="__nav_7_4_label" tabindex="0">
<span class="md-ellipsis">
    LLM
    
  </span>
<span class="md-nav__icon md-icon"></span>
</label>
<nav aria-expanded="false" aria-labelledby="__nav_7_4_label" class="md-nav" data-md-level="2">
<label class="md-nav__title" for="__nav_7_4">
<span class="md-nav__icon md-icon"></span>
            LLM
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../Paper/GPT-1/">
<span class="md-ellipsis">
    GPT-1
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../Paper/GPT-2/">
<span class="md-ellipsis">
    GPT-2
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../Paper/GPT-3/">
<span class="md-ellipsis">
    GPT-3
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../Paper/LLM2Vec/">
<span class="md-ellipsis">
    LLM2Vec
    
  </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--nested">
<input class="md-nav__toggle md-toggle" id="__nav_7_5" type="checkbox"/>
<label class="md-nav__link" for="__nav_7_5" id="__nav_7_5_label" tabindex="0">
<span class="md-ellipsis">
    Accelerators
    
  </span>
<span class="md-nav__icon md-icon"></span>
</label>
<nav aria-expanded="false" aria-labelledby="__nav_7_5_label" class="md-nav" data-md-level="2">
<label class="md-nav__title" for="__nav_7_5">
<span class="md-nav__icon md-icon"></span>
            Accelerators
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../Paper/FAST/">
<span class="md-ellipsis">
    FAST
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../Paper/softmax/">
<span class="md-ellipsis">
    Softmax 加速
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../Paper/NN-LUT/">
<span class="md-ellipsis">
    NN-LUT
    
  </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--nested">
<input class="md-nav__toggle md-toggle" id="__nav_7_6" type="checkbox"/>
<label class="md-nav__link" for="__nav_7_6" id="__nav_7_6_label" tabindex="0">
<span class="md-ellipsis">
    CGRA
    
  </span>
<span class="md-nav__icon md-icon"></span>
</label>
<nav aria-expanded="false" aria-labelledby="__nav_7_6_label" class="md-nav" data-md-level="2">
<label class="md-nav__title" for="__nav_7_6">
<span class="md-nav__icon md-icon"></span>
            CGRA
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../Paper/VecPAC/">
<span class="md-ellipsis">
    VecPAC
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../Paper/APEX/">
<span class="md-ellipsis">
    APEX
    
  </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--nested">
<input class="md-nav__toggle md-toggle" id="__nav_7_7" type="checkbox"/>
<label class="md-nav__link" for="__nav_7_7" id="__nav_7_7_label" tabindex="0">
<span class="md-ellipsis">
    Diffusion
    
  </span>
<span class="md-nav__icon md-icon"></span>
</label>
<nav aria-expanded="false" aria-labelledby="__nav_7_7_label" class="md-nav" data-md-level="2">
<label class="md-nav__title" for="__nav_7_7">
<span class="md-nav__icon md-icon"></span>
            Diffusion
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../Paper/T2I_RL/">
<span class="md-ellipsis">
    Diffusion + RL
    
  </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--nested">
<input class="md-nav__toggle md-toggle" id="__nav_7_8" type="checkbox"/>
<label class="md-nav__link" for="__nav_7_8" id="__nav_7_8_label" tabindex="0">
<span class="md-ellipsis">
    Compilation
    
  </span>
<span class="md-nav__icon md-icon"></span>
</label>
<nav aria-expanded="false" aria-labelledby="__nav_7_8_label" class="md-nav" data-md-level="2">
<label class="md-nav__title" for="__nav_7_8">
<span class="md-nav__icon md-icon"></span>
            Compilation
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../Paper/Seer/">
<span class="md-ellipsis">
    SEER
    
  </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--nested">
<input class="md-nav__toggle md-toggle" id="__nav_7_9" type="checkbox"/>
<label class="md-nav__link" for="__nav_7_9" id="__nav_7_9_label" tabindex="0">
<span class="md-ellipsis">
    Others
    
  </span>
<span class="md-nav__icon md-icon"></span>
</label>
<nav aria-expanded="false" aria-labelledby="__nav_7_9_label" class="md-nav" data-md-level="2">
<label class="md-nav__title" for="__nav_7_9">
<span class="md-nav__icon md-icon"></span>
            Others
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../Paper/BiS-KM/">
<span class="md-ellipsis">
    BiS-KM
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../Paper/ChatEDA/">
<span class="md-ellipsis">
    ChatEDA
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../Paper/CLIP/">
<span class="md-ellipsis">
    CLIP
    
  </span>
</a>
</li>
</ul>
</nav>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--nested">
<input class="md-nav__toggle md-toggle" id="__nav_8" type="checkbox"/>
<div class="md-nav__link md-nav__container">
<a class="md-nav__link" href="../../Misc/">
<span class="md-ellipsis">
    Miscellaneous
    
  </span>
</a>
<label class="md-nav__link" for="__nav_8" id="__nav_8_label" tabindex="0">
<span class="md-nav__icon md-icon"></span>
</label>
</div>
<nav aria-expanded="false" aria-labelledby="__nav_8_label" class="md-nav" data-md-level="1">
<label class="md-nav__title" for="__nav_8">
<span class="md-nav__icon md-icon"></span>
            Miscellaneous
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../Misc/float/">
<span class="md-ellipsis">
    浮点数与定点数
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../Misc/fpga/">
<span class="md-ellipsis">
    FPGA Programming
    
  </span>
</a>
</li>
<li class="md-nav__item md-nav__item--nested">
<input class="md-nav__toggle md-toggle" id="__nav_8_4" type="checkbox"/>
<label class="md-nav__link" for="__nav_8_4" id="__nav_8_4_label" tabindex="0">
<span class="md-ellipsis">
    LLVM
    
  </span>
<span class="md-nav__icon md-icon"></span>
</label>
<nav aria-expanded="false" aria-labelledby="__nav_8_4_label" class="md-nav" data-md-level="2">
<label class="md-nav__title" for="__nav_8_4">
<span class="md-nav__icon md-icon"></span>
            LLVM
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../Misc/LLVM/ir/">
<span class="md-ellipsis">
    LLVM IR
    
  </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--nested">
<input class="md-nav__toggle md-toggle" id="__nav_8_5" type="checkbox"/>
<label class="md-nav__link" for="__nav_8_5" id="__nav_8_5_label" tabindex="0">
<span class="md-ellipsis">
    CGRA
    
  </span>
<span class="md-nav__icon md-icon"></span>
</label>
<nav aria-expanded="false" aria-labelledby="__nav_8_5_label" class="md-nav" data-md-level="2">
<label class="md-nav__title" for="__nav_8_5">
<span class="md-nav__icon md-icon"></span>
            CGRA
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../Misc/CGRA/intro/">
<span class="md-ellipsis">
    CGRA 介绍
    
  </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--nested">
<input class="md-nav__toggle md-toggle" id="__nav_8_6" type="checkbox"/>
<label class="md-nav__link" for="__nav_8_6" id="__nav_8_6_label" tabindex="0">
<span class="md-ellipsis">
    PIM
    
  </span>
<span class="md-nav__icon md-icon"></span>
</label>
<nav aria-expanded="false" aria-labelledby="__nav_8_6_label" class="md-nav" data-md-level="2">
<label class="md-nav__title" for="__nav_8_6">
<span class="md-nav__icon md-icon"></span>
            PIM
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../Misc/PIM/upmem/">
<span class="md-ellipsis">
    PIM 架构介绍
    
  </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--nested">
<input class="md-nav__toggle md-toggle" id="__nav_8_7" type="checkbox"/>
<label class="md-nav__link" for="__nav_8_7" id="__nav_8_7_label" tabindex="0">
<span class="md-ellipsis">
    Android
    
  </span>
<span class="md-nav__icon md-icon"></span>
</label>
<nav aria-expanded="false" aria-labelledby="__nav_8_7_label" class="md-nav" data-md-level="2">
<label class="md-nav__title" for="__nav_8_7">
<span class="md-nav__icon md-icon"></span>
            Android
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../android/dataflow/">
<span class="md-ellipsis">
    触控事件的数据流
    
  </span>
</a>
</li>
</ul>
</nav>
</li>
</ul>
</nav>
</li>
</ul>
</nav>
</div>
</div>
</div>
<div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc">
<div class="md-sidebar__scrollwrap">
<div class="md-sidebar__inner">
<nav aria-label="目录" class="md-nav md-nav--secondary">
<label class="md-nav__title" for="__toc">
<span class="md-nav__icon md-icon"></span>
      目录
    </label>
<ul class="md-nav__list" data-md-component="toc" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="#transformer-basics">
<span class="md-ellipsis">
      Transformer Basics
    </span>
</a>
<nav aria-label="Transformer Basics" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#revist-nlp-tasks">
<span class="md-ellipsis">
      Revist: NLP Tasks
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#transformer">
<span class="md-ellipsis">
      Transformer
    </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#transformer-design-variants">
<span class="md-ellipsis">
      Transformer Design Variants
    </span>
</a>
<nav aria-label="Transformer Design Variants" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#encoder-decoder">
<span class="md-ellipsis">
      Encoder &amp; Decoder
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#positional-encoding">
<span class="md-ellipsis">
      Positional Encoding
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#kv-cache-optimizations">
<span class="md-ellipsis">
      KV Cache Optimizations
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#improving-over-ffn">
<span class="md-ellipsis">
      Improving over FFN
    </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#large-language-models-llms">
<span class="md-ellipsis">
      Large language models (LLMs)
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#efficient-inference-algorithms-for-llms">
<span class="md-ellipsis">
      Efficient inference algorithms for LLMs
    </span>
</a>
<nav aria-label="Efficient inference algorithms for LLMs" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#quantization">
<span class="md-ellipsis">
      Quantization
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#pruningsparsity">
<span class="md-ellipsis">
      Pruning/Sparsity
    </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#efficient-inference-systems-for-llms">
<span class="md-ellipsis">
      Efficient inference systems for LLMs
    </span>
</a>
<nav aria-label="Efficient inference systems for LLMs" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#vllm-and-paged-attention">
<span class="md-ellipsis">
      vLLM and Paged Attention
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#streamingllm">
<span class="md-ellipsis">
      StreamingLLM
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#flashattention">
<span class="md-ellipsis">
      FlashAttention
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#speculative-decoding">
<span class="md-ellipsis">
      Speculative Decoding
    </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#efficient-fine-tuning-for-llms">
<span class="md-ellipsis">
      Efficient fine-tuning for LLMs
    </span>
</a>
</li>
</ul>
</nav>
</div>
</div>
</div>
<div class="md-content" data-md-component="content">
<article class="md-content__inner md-typeset">
<h1 id="transformer-and-llm">Transformer and LLM<a class="headerlink" href="#transformer-and-llm" title="Permanent link">¶</a></h1>
<div style="margin-top: -30px; font-size: 0.75em; opacity: 0.7;">
<p><span class="twemoji"><svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M12 2A10 10 0 0 0 2 12a10 10 0 0 0 10 10 10 10 0 0 0 10-10h-2a8 8 0 0 1-8 8 8 8 0 0 1-8-8 8 8 0 0 1 8-8zm6.78 1a.7.7 0 0 0-.48.2l-1.22 1.21 2.5 2.5L20.8 5.7c.26-.26.26-.7 0-.95L19.25 3.2c-.13-.13-.3-.2-.47-.2m-2.41 2.12L9 12.5V15h2.5l7.37-7.38z"></path></svg></span> 约<span class="heti-skip"><span class="heti-spacing"> </span>4390<span class="heti-spacing"> </span></span>个字 <span class="twemoji"><svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M21 17H7V3h14m0-2H7a2 2 0 0 0-2 2v14a2 2 0 0 0 2 2h14a2 2 0 0 0 2-2V3a2 2 0 0 0-2-2M3 5H1v16a2 2 0 0 0 2 2h16v-2H3m12.96-10.71-2.75 3.54-1.96-2.36L8.5 15h11z"></path></svg></span> <span>48<span class="heti-spacing"> </span></span>张图片 <span class="twemoji"><svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M12 20c4.42 0 8-3.58 8-8s-3.58-8-8-8-8 3.58-8 8 3.58 8 8 8m0-18c5.5 0 10 4.5 10 10s-4.5 10-10 10C6.47 22 2 17.5 2 12S6.5 2 12 2m.5 11H11V7h1.5v4.26l3.7-2.13.75 1.3z"></path></svg></span> 预计阅读时间<span class="heti-skip"><span class="heti-spacing"> </span>15<span class="heti-spacing"> </span></span>分钟</p>
</div>
<div class="admonition abstract">
<p class="admonition-title">Abstract</p>
<ul>
<li>Transformer basics </li>
<li>Transformer design variants</li>
<li>Large language models (LLMs)</li>
<li>Efficient inference algorithms for LLMs <ul>
<li>Quantization: SmoothQuant, AWQ, TinyChat</li>
<li>Pruning/sparsity: SpAtten, H2O, MoE</li>
</ul>
</li>
<li>Efficient inference systems for LLMs <ul>
<li>vLLM</li>
<li>StreamingLLM</li>
<li>FlashAttention</li>
<li>Speculative decoding</li>
</ul>
</li>
<li>Efficient fine-tuning for LLMs <ul>
<li>LoRA/QLoRA</li>
<li>Adapter</li>
<li>Prompt Tuning</li>
</ul>
</li>
</ul>
</div>
<h2 id="transformer-basics">Transformer Basics<a class="headerlink" href="#transformer-basics" title="Permanent link">¶</a></h2>
<h3 id="revist-nlp-tasks">Revist: NLP Tasks<a class="headerlink" href="#revist-nlp-tasks" title="Permanent link">¶</a></h3>
<ul>
<li>
<p><span>NLP<span class="heti-spacing"> </span></span>里主要有两类任务：</p>
<ul>
<li><span>Discriminative tasks<span class="heti-spacing"> </span></span>判别任务，比如文本分类、命名实体识别、情感分析等。</li>
<li><span>Generative tasks<span class="heti-spacing"> </span></span>生成任务，比如机器翻译、文本摘要、对话生成等。</li>
</ul>
<p></p><div align="center"> <img src="https://cdn.hobbitqia.cc/20240608150515.png" width="75%/"/> </div>
</li>
<li>
<p>在<span class="heti-skip"><span class="heti-spacing"> </span>Transformer<span class="heti-spacing"> </span></span>出来之前，常用的模型有：</p>
<ul>
<li>
<p><strong>Recurrent Neural Networks (RNNs)</strong></p>
<ul>
<li>当前的状态依赖于输入和之前的状态，因此存在<span class="heti-skip"><span class="heti-spacing"> </span>cross-token<span class="heti-spacing"> </span></span>的依赖，限制了他的<span><span class="heti-spacing"> </span>scalability</span>。</li>
<li><span>work memory<span class="heti-spacing"> </span></span>努力保持<span><span class="heti-spacing"> </span>long-term dependencies</span>（可以由<span class="heti-skip"><span class="heti-spacing"> </span>LSTM<span class="heti-spacing"> </span></span>解决<heti-adjacent class="heti-adjacent-half">）</heti-adjacent>。</li>
</ul>
<p></p><div align="center"> <img src="https://cdn.hobbitqia.cc/20240608150824.png" width="85%/"/> </div>
</li>
<li>
<p><strong>Convolutional Neural Networks (CNNs)</strong></p>
<ul>
<li><span>tokens<span class="heti-spacing"> </span></span>之间不存在依赖，因此有更好的<span><span class="heti-spacing"> </span>scalability</span>。</li>
<li>但限制了上下文信息，导致模型的能力不如<span><span class="heti-spacing"> </span>RNN</span><heti-adjacent class="heti-adjacent-half">。</heti-adjacent>（因为<span class="heti-skip"><span class="heti-spacing"> </span>CV<span class="heti-spacing"> </span></span>中信息往往都具有局部性，但是<span class="heti-skip"><span class="heti-spacing"> </span>NLP<span class="heti-spacing"> </span></span>的任务不一定具有这个特点） </li>
</ul>
<p></p><div align="center"> <img src="https://cdn.hobbitqia.cc/20240608151009.png" width="65%/"/> </div>
</li>
<li>
<p>NLP with RNN/LSTM</p>
<ul>
<li><span>Bi-directional RNNs<span class="heti-spacing"> </span></span>用来做判别任务（encoding<heti-adjacent class="heti-adjacent-half">）</heti-adjacent>。双向体现在可以同时看到以前和未来位置的信息，相当于离线处理。</li>
<li><span>Uni-directional RNNs<span class="heti-spacing"> </span></span>用来做生成任务（decoding<heti-adjacent class="heti-adjacent-half">）</heti-adjacent>。单向体现在只能看到以前的信息，相当于在线处理。</li>
</ul>
</li>
<li>Problems with RNN/LSTM<ul>
<li>难以建模长期的关系，需要<span class="heti-skip"><span class="heti-spacing"> </span><span class="arithmatex">\(O(seq\_len)\)</span><span class="heti-spacing"> </span></span>步才能建立两个<span class="heti-skip"><span class="heti-spacing"> </span>tokens<span class="heti-spacing"> </span></span>间的相互联系。</li>
<li>训练时的并行性差，因为状态总是严格依赖于之前的状态，需要<span class="heti-skip"><span class="heti-spacing"> </span>n<span class="heti-spacing"> </span></span>步才能到达状态<span><span class="heti-spacing"> </span>n</span>。</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="transformer">Transformer<a class="headerlink" href="#transformer" title="Permanent link">¶</a></h3>
<div align="center"> <img src="https://cdn.hobbitqia.cc/20240608235853.png" width="100%/"/> </div>
<ul>
<li>
<p><strong>Tokenization</strong></p>
<ul>
<li>A tokenizer maps a word to one/multiple tokens. </li>
</ul>
<details class="example">
<summary>Example</summary>
<p>如下图，把<span class="heti-skip"><span class="heti-spacing"> </span>110<span class="heti-spacing"> </span></span>个单词划分为了<span class="heti-skip"><span class="heti-spacing"> </span>162<span class="heti-spacing"> </span></span>个<span><span class="heti-spacing"> </span>tokens</span>。
</p><div align="center"> <img src="https://cdn.hobbitqia.cc/20240608152440.png" width="70%/"/> </div>
</details>
</li>
<li>
<p><strong>Word Representation</strong></p>
<ul>
<li><strong>One-Hot Encoding</strong><ul>
<li>一个词被表示为一个长度为词典大小的向量，只有一个位置为<span><span class="heti-spacing"> </span>1</span>，其余为<span><span class="heti-spacing"> </span>0</span>。</li>
<li>但是对于大词典，向量可能会变得非常长，而且除了一个地方其余位置全是<span><span class="heti-spacing"> </span>0</span>，这被认为是一种非常稀疏的表示方法。</li>
</ul>
</li>
<li>
<p><strong>Word Embedding</strong></p>
<ul>
<li>
<p>把单词的索引，通过一个<span class="heti-skip"><span class="heti-spacing"> </span>look-up table<span class="heti-spacing"> </span></span>映射到一个连续的词嵌入。即我们可以把一个单词就看做一个向量。</p>
<details class="example">
<summary>Example</summary>
<p></p><div align="center"> <img src="https://cdn.hobbitqia.cc/20240608152653.png" width="40%/"/> </div>
</details>
</li>
<li>
<p>词嵌入可以<span class="heti-skip"><span class="heti-spacing"> </span>end-to-end<span class="heti-spacing"> </span></span>进行训练，来适配对应模型的下游任务。流行的预训练的词嵌入有<span><span class="heti-spacing"> </span>Word2Vec, GloVe</span>。</p>
</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>Multi-Head Attention(MHA)</strong></p>
<ul>
<li>
<p><strong>Self-Attention</strong>: <span class="arithmatex">\(Attention(Q,K,V)=Softmax(\frac{QK^\top}{\sqrt{d_k}})V\)</span></p>
<p></p><div align="center"> <img src="https://cdn.hobbitqia.cc/20240608220338.png" width="45%/"/> </div>
<ul>
<li>首先把嵌入<span class="heti-skip"><span class="heti-spacing"> </span><span class="arithmatex">\(E\)</span><span class="heti-spacing"> </span></span>投影为<span><span class="heti-spacing"> </span>query, key, value <span class="arithmatex">\((Q,K,V)\)</span></span>。</li>
<li>将<span class="heti-skip"><span class="heti-spacing"> </span><span class="arithmatex">\(Q,K\)</span><span class="heti-spacing"> </span></span>乘起来得到内积，并除以<span class="heti-skip"><span class="heti-spacing"> </span><span class="arithmatex">\(\sqrt{d_k}\)</span><span class="heti-spacing"> </span></span>来规格化。</li>
<li>经过<span class="heti-skip"><span class="heti-spacing"> </span>softmax<span class="heti-spacing"> </span></span>来得到<span class="heti-skip"><span class="heti-spacing"> </span><span class="arithmatex">\(N\times N\)</span><span class="heti-spacing"> </span></span>的<span class="heti-skip"><span class="heti-spacing"> </span>attention<span class="heti-spacing"> </span></span>权重（<span>attention<span class="heti-spacing"> </span></span>计算的复杂度是<span><span class="heti-spacing"> </span><span class="arithmatex">\(O(N^2)\)</span></span><heti-adjacent class="heti-adjacent-half">）</heti-adjacent>。<ul>
<li><span>softmax<span class="heti-spacing"> </span></span>是为了将权重视为概率，使得权重和为<span><span class="heti-spacing"> </span>1</span>。</li>
</ul>
</li>
<li>最后将<span class="heti-skip"><span class="heti-spacing"> </span>attention weights<span class="heti-spacing"> </span></span>与<span class="heti-skip"><span class="heti-spacing"> </span><span class="arithmatex">\(V\)</span><span class="heti-spacing"> </span></span>相乘得到输出。</li>
</ul>
<div class="admonition example">
<p class="admonition-title">Example</p>
<p><span>(Q, K, V)<span class="heti-spacing"> </span></span>可以类比于一个<span class="heti-skip"><span class="heti-spacing"> </span>Youtube<span class="heti-spacing"> </span></span>搜索的过程：<span>Query<span class="heti-spacing"> </span></span>是我们在搜索框输入的内容，<span>Key<span class="heti-spacing"> </span></span>是<span class="heti-skip"><span class="heti-spacing"> </span>Youtube<span class="heti-spacing"> </span></span>上所有视频的标题或者描述，<span>Value<span class="heti-spacing"> </span></span>是对应的视频。我们通过<span class="heti-skip"><span class="heti-spacing"> </span>Query<span class="heti-spacing"> </span></span>和<span class="heti-skip"><span class="heti-spacing"> </span>Key<span class="heti-spacing"> </span></span>的相似度来计算出每个视频的权重，最后将权重和视频相乘得到最终的输出。</p>
</div>
</li>
<li>
<p><strong>MHA</strong>: Each head captures different semantics</p>
<ul>
<li>我们需要不同的注意力映射来捕捉不同的语义关系，因此我们使用了多头注意力机制。</li>
<li>
<p>模型有<span><span class="heti-spacing"> </span><span class="arithmatex">\(H&gt;1\)</span> attention heads</span>（<span><span class="arithmatex">\(QKV\)</span><span class="heti-spacing"> </span></span>的并行分支<heti-adjacent class="heti-adjacent-half">）</heti-adjacent>，最终结果由不同的注意力结果拼接而成。</p>
<div class="arithmatex">\[
\begin{aligned}
MultiHead(Q,K,V) &amp; =Concat(head_1, /ldots, head_h)W^O\\
    where\ head_i &amp; =Attention(QW_i^Q,KW_i^K,VW_i^V)
\end{aligned}
\]</div>
<p></p><div align="center"> <img src="https://cdn.hobbitqia.cc/20240608232752.png" width="45%/"/> </div>
</li>
</ul>
</li>
<li>
<p><strong>Attention Masking</strong></p>
<p>有<span class="heti-skip"><span class="heti-spacing"> </span>global/causal<span class="heti-spacing"> </span></span>两种<span><span class="heti-spacing"> </span>mask</span>，其中<span class="heti-skip"><span class="heti-spacing"> </span>global<span class="heti-spacing"> </span></span>能看到前后的值，但是<span class="heti-skip"><span class="heti-spacing"> </span>causal<span class="heti-spacing"> </span></span>只能看到之前的值。
</p><div align="center"> <img src="https://cdn.hobbitqia.cc/20240608233401.png" width="40%/"/> </div>
</li>
</ul>
</li>
<li>
<p><strong>Feed-Forward Network (FFN)</strong></p>
<ul>
<li>自注意力只建立了<span class="heti-skip"><span class="heti-spacing"> </span>tokens<span class="heti-spacing"> </span></span>之间的关系，没有涉及到<span><span class="heti-spacing"> </span>elementwise non-linearity.</span></li>
<li>因此我们添加了一个前馈神经网络来帮助特征的建模。</li>
<li>
<p>朴素实现就是一个<span class="heti-skip"><span class="heti-spacing"> </span>2<span class="heti-spacing"> </span></span>层<span><span class="heti-spacing"> </span>MLP</span>（隐藏状态维度更大）以及使用<span class="heti-skip"><span class="heti-spacing"> </span>ReLU/GeLU<span class="heti-spacing"> </span></span>作为激活函数。</p>
<div class="arithmatex">\[
FFN(x)=ReLU(xW_1+b_1)W_2+b_2
\]</div>
<p></p><div align="center"> <img src="https://cdn.hobbitqia.cc/20240608234020.png" width="35%/"/> </div>
</li>
</ul>
</li>
<li>
<p><strong>LayerNorm &amp; Residual connection</strong></p>
<ul>
<li>
<p><span>Layer Normalization(LN)<span class="heti-spacing"> </span></span>对每个<span class="heti-skip"><span class="heti-spacing"> </span>token<span class="heti-spacing"> </span></span>进行规范化，随后作用仿射变化<heti-adjacent class="heti-adjacent-half">。</heti-adjacent>（<span>BatchNorm<span class="heti-spacing"> </span></span>会对整个<span class="heti-skip"><span class="heti-spacing"> </span>batch<span class="heti-spacing"> </span></span>进行规范化）</p>
<div class="arithmatex">\[
LN(x)=\frac{x-\mu}{\sqrt{\sigma^2+\epsilon}}*\gamma+\beta
\]</div>
<p>这里的放射变化的参数是可学习的。</p>
</li>
<li>
<p>Transformer Block</p>
<ul>
<li>我们会添加<span class="heti-skip"><span class="heti-spacing"> </span>LayerNorm<span class="heti-spacing"> </span></span>和<span class="heti-skip"><span class="heti-spacing"> </span>Residual Connections<span class="heti-spacing"> </span></span>来促进训练的稳定性。</li>
<li>
<p>有两种放置方法：<span>Post-norm<span class="heti-spacing"> </span></span>和<span><span class="heti-spacing"> </span>Pre-norm</span>，现在更多地使用<span><span class="heti-spacing"> </span>Pre-norm</span>。</p>
<p></p><div align="center"> <img src="https://cdn.hobbitqia.cc/20240608234440.png" width="90%/"/> </div>
</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>Positional Encoding (PE)</strong></p>
<ul>
<li>问题：<span>attention<span class="heti-spacing"> </span></span>和<span class="heti-skip"><span class="heti-spacing"> </span>FFN<span class="heti-spacing"> </span></span>并没有区分输入<span class="heti-skip"><span class="heti-spacing"> </span>token<span class="heti-spacing"> </span></span>的次序，即将输入<span class="heti-skip"><span class="heti-spacing"> </span>token<span class="heti-spacing"> </span></span>打乱顺序后得到的结果是一样的。相当于我们只是对<span class="heti-skip"><span class="heti-spacing"> </span>set encoding<span class="heti-spacing"> </span></span>而非<span><span class="heti-spacing"> </span>sequence encoding</span>。</li>
<li>
<p>解决方法：位置编码，即为每个<span class="heti-skip"><span class="heti-spacing"> </span>token<span class="heti-spacing"> </span></span>添加一个位置信息。</p>
<ul>
<li>
<p>每个单词的在句子中的位置都有一个独一无二的<span><span class="heti-spacing"> </span>encoding</span>。</p>
<div class="arithmatex">\[
\vec{p_t}^{(i)} = f(t)^{(i)} := \begin{cases}
\sin(w_k\cdot t) &amp; \text{if $i=2k$} \\
\cos(w_k\cdot t) &amp; \text{if $i=2k+1$}
\end{cases}, w_k=(10000^{2k/d})
\]</div>
</li>
<li>
<p>我们将位置编码和词嵌入相加，得到最终的输入。</p>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="transformer-design-variants">Transformer Design Variants<a class="headerlink" href="#transformer-design-variants" title="Permanent link">¶</a></h2>
<ul>
<li>大部分从最初的<span class="heti-skip"><span class="heti-spacing"> </span>transformer paper<span class="heti-spacing"> </span></span>中的设计都已经被社区广泛使用。</li>
<li>但是，有一些变种的<span class="heti-skip"><span class="heti-spacing"> </span>transformer<span class="heti-spacing"> </span></span>也被提出：<ul>
<li>Encoder-decoder(T5), encoder-only(BERT), decoder-only(GPT)</li>
<li>Absolute positional encoding =&gt; Relative positional encoding</li>
<li>KV cache optimizations<ul>
<li>Multi-Head Attention (MHA) -&gt; Multi-Query Attention (MQA) -&gt; Grouped-Query Attention (GQA)</li>
</ul>
</li>
<li>FFN -&gt; GLU (gated linear unit)</li>
</ul>
</li>
</ul>
<h3 id="encoder-decoder">Encoder &amp; Decoder<a class="headerlink" href="#encoder-decoder" title="Permanent link">¶</a></h3>
<ul>
<li>
<p><strong>Encoder-Decoder</strong></p>
<ul>
<li>原始的<span class="heti-skip"><span class="heti-spacing"> </span>transformer<span class="heti-spacing"> </span></span>就是一个<span class="heti-skip"><span class="heti-spacing"> </span>Encoder-Decoder<span class="heti-spacing"> </span></span>结构。</li>
<li><span>T5<span class="heti-spacing"> </span></span>提供了一个统一的<span class="heti-skip"><span class="heti-spacing"> </span>text-to-text<span class="heti-spacing"> </span></span>的模型，可以在不同的<span class="heti-skip"><span class="heti-spacing"> </span>NLP<span class="heti-spacing"> </span></span>任务上进行迁移学习。</li>
<li>
<p><span>prompt<span class="heti-spacing"> </span></span>会被送到<span class="heti-skip"><span class="heti-spacing"> </span>encoder<span class="heti-spacing"> </span></span>中，<span>decoder<span class="heti-spacing"> </span></span>会生成答案。</p>
<p></p><div align="center"> <img src="https://cdn.hobbitqia.cc/20240609101930.png" width="85%/"/> </div>
</li>
</ul>
</li>
<li>
<p><strong>Encoder-Only (BERT)</strong></p>
<ul>
<li><span>Bidirectional Encoder Representations from Transformers (BERT)<span class="heti-spacing"> </span></span>是一个<span class="heti-skip"><span class="heti-spacing"> </span>encoder-only<span class="heti-spacing"> </span></span>的预训练模型。</li>
<li>有两个预训练任务：<span>Masked Language Model (MLM)<span class="heti-spacing"> </span></span>和<span><span class="heti-spacing"> </span>Next Sentence Prediction (NSP)</span>。<span>MLM<span class="heti-spacing"> </span></span>类似于完形填空，即通过看上下文来决定被<span class="heti-skip"><span class="heti-spacing"> </span>mask<span class="heti-spacing"> </span></span>的词是什么；<span>NSP<span class="heti-spacing"> </span></span>是判断两个句子是否是连续的。</li>
<li>预训练模型通过<span class="heti-skip"><span class="heti-spacing"> </span>fine-tune<span class="heti-spacing"> </span></span>来适配对应的下游任务。</li>
</ul>
<p></p><div align="center"> <img src="https://cdn.hobbitqia.cc/20240609102130.png" width="75%/"/> </div>
</li>
<li>
<p><strong>Decoder-only (GPT)</strong></p>
<ul>
<li><span>Generative Pre-trained Transformer (GPT)<span class="heti-spacing"> </span></span>是一个<span class="heti-skip"><span class="heti-spacing"> </span>decoder-only<span class="heti-spacing"> </span></span>的预训练模型。</li>
<li>预训练的目标是<span><span class="heti-spacing"> </span>Next word prediction</span>，即给定前面的词，预测下一个词。</li>
<li>对于小模型（比如<span><span class="heti-spacing"> </span>GPT-2</span><heti-adjacent class="heti-adjacent-half">）</heti-adjacent>，预训练模型需要通过<span class="heti-skip"><span class="heti-spacing"> </span>fine-tune<span class="heti-spacing"> </span></span>来适配对应的下游任务。更大的模型可以<span class="heti-skip"><span class="heti-spacing"> </span>zero-shot/few-shot<span class="heti-spacing"> </span></span>适配下游任务，不再需要微调。</li>
</ul>
<p></p><div align="center"> <img src="https://cdn.hobbitqia.cc/20240609102306.png" width="75%/"/> </div>
</li>
</ul>
<h3 id="positional-encoding">Positional Encoding<a class="headerlink" href="#positional-encoding" title="Permanent link">¶</a></h3>
<ul>
<li>Absolute Positional Encoding<ul>
<li>绝对位置编码把位置信息直接加到词嵌入上，因此会同时影响<span><span class="heti-spacing"> </span>Q K V</span>，整个模型里面都会有位置信息。</li>
</ul>
</li>
<li>Relative Positional Encoding<ul>
<li>相对位置编码将位置信息加到<span class="heti-skip"><span class="heti-spacing"> </span>attention score<span class="heti-spacing"> </span></span>上，因此只会影响<span><span class="heti-spacing"> </span>Q K</span>，不会影响<span><span class="heti-spacing"> </span>V</span>。好处是可以更好地泛化序列长度，即<span><span class="heti-spacing"> </span>train short, test long.</span></li>
<li>
<p><strong>Attention with Linear Biases (ALiBi)</strong></p>
<ul>
<li>
<p>使用相对距离来代替绝对的索引。将偏移量加到<span class="heti-skip"><span class="heti-spacing"> </span>attention matrix<span class="heti-spacing"> </span></span>上，再做<span class="heti-skip"><span class="heti-spacing"> </span>softmax<span class="heti-spacing"> </span></span>操作并与<span class="heti-skip"><span class="heti-spacing"> </span>V<span class="heti-spacing"> </span></span>相乘。</p>
<p></p><div align="center"> <img src="https://cdn.hobbitqia.cc/20240609103745.png" width="75%/"/> </div>
</li>
<li>
<p><strong>Rotary Positional Embedding (RoPE)</strong></p>
<ul>
<li>
<p>把<span class="heti-skip"><span class="heti-spacing"> </span>embedding<span class="heti-spacing"> </span></span>在<span class="heti-skip"><span class="heti-spacing"> </span>2D<span class="heti-spacing"> </span></span>空间里旋转：首先将<span class="heti-skip"><span class="heti-spacing"> </span><span class="arithmatex">\(d\)</span><span class="heti-spacing"> </span></span>维的<span class="heti-skip"><span class="heti-spacing"> </span>embedding<span class="heti-spacing"> </span></span>分为<span class="heti-skip"><span class="heti-spacing"> </span><span class="arithmatex">\(d/2\)</span><span class="heti-spacing"> </span></span>对，每对认为是一个<span class="heti-skip"><span class="heti-spacing"> </span>2D<span class="heti-spacing"> </span></span>的坐标。随后根据位置<span class="heti-skip"><span class="heti-spacing"> </span><span class="arithmatex">\(m\)</span><span class="heti-spacing"> </span></span>将这个坐标旋转<span class="heti-skip"><span class="heti-spacing"> </span><span class="arithmatex">\(m\theta\)</span><span class="heti-spacing"> </span></span>度。</p>
<p></p><div align="center"> <img src="https://cdn.hobbitqia.cc/20240609104101.png" width="100%/"/> </div>
</li>
<li>
<p>一般形式可以写作：</p>
<p></p><div align="center"> <img src="https://cdn.hobbitqia.cc/20240609104145.png" width="90%/"/> </div>
</li>
<li>
<p>好处是<span class="heti-skip"><span class="heti-spacing"> </span>LLM<span class="heti-spacing"> </span></span>通常训练时都有上下文长度的限制 <strong><em>e.g.</em></strong> <span>2k for LLaMA, 4k for LLaMA-2, 8k for GPT-4.<span class="heti-spacing"> </span></span>我们可以延长上下文长度，通过插值<span class="heti-skip"><span class="heti-spacing"> </span>RoPE PE<span class="heti-spacing"> </span></span>来实现<heti-adjacent class="heti-adjacent-half">。</heti-adjacent>（即使用更小的<span><span class="heti-spacing"> </span><span class="arithmatex">\(\theta_i\)</span></span>）</p>
<div class="admonition example">
<p class="admonition-title">Extend the context length of LLaMA from 2k to 32k</p>
<p></p><div align="center"> <img src="https://cdn.hobbitqia.cc/20240609104343.png" width="100%/"/> </div>
</div>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="kv-cache-optimizations">KV Cache Optimizations<a class="headerlink" href="#kv-cache-optimizations" title="Permanent link">¶</a></h3>
<ul>
<li>
<p>The <strong>KV cache</strong> could be large with long context.</p>
<ul>
<li>在<span class="heti-skip"><span class="heti-spacing"> </span>transformer decoding<span class="heti-spacing"> </span></span>中，我们需要存储所有之前<span class="heti-skip"><span class="heti-spacing"> </span>tokens<span class="heti-spacing"> </span></span>的<span class="heti-skip"><span class="heti-spacing"> </span>key<span class="heti-spacing"> </span></span>和<span><span class="heti-spacing"> </span>value</span>，以此来计算<span><span class="heti-spacing"> </span>attention</span>，这就是<span><span class="heti-spacing"> </span>KV cache</span>。</li>
<li>
<p>随着上下文长度的增加，<span>KV cache<span class="heti-spacing"> </span></span>会变得非常大，因此我们需要一些优化来减少存储空间。</p>
<div class="admonition example">
<p class="admonition-title">Example</p>
<p></p><div align="center"> <img src="https://cdn.hobbitqia.cc/20240609104655.png" width="90%/"/> </div>
<div align="center"> <img src="https://cdn.hobbitqia.cc/20240609104713.png" width="80%/"/> </div>
</div>
</li>
</ul>
</li>
<li>
<p><strong>Multi-Query Attention</strong></p>
<ul>
<li>通过减少 <code>#kv-heads</code> 来降低<span class="heti-skip"><span class="heti-spacing"> </span>KV cache<span class="heti-spacing"> </span></span>的大小。</li>
<li><strong>Multi-head attention (MHA)</strong>: <span class="arithmatex">\(N\)</span> heads for query, <span class="arithmatex">\(N\)</span> heads for key/value</li>
<li><strong>Multi-query attention (MQA)</strong>: <span class="arithmatex">\(N\)</span> heads for query, 1 heads for key/value</li>
<li><strong>Grouped-query attention (GQA)</strong>: <span class="arithmatex">\(N\)</span> heads for query, <span class="arithmatex">\(G\)</span> heads for key/value (typically <span class="arithmatex">\(G=N/8\)</span>)</li>
</ul>
<p></p><div align="center"> <img src="https://cdn.hobbitqia.cc/20240609104903.png" width="85%/"/> </div>
<div align="center"> <img src="https://cdn.hobbitqia.cc/20240609104913.png" width="70%/"/> </div>
</li>
</ul>
<h3 id="improving-over-ffn">Improving over FFN<a class="headerlink" href="#improving-over-ffn" title="Permanent link">¶</a></h3>
<ul>
<li>
<p><strong>Gated Linear Units (GLU)</strong></p>
<ul>
<li>
<p>我们可以使用<span class="heti-skip"><span class="heti-spacing"> </span>GLU<span class="heti-spacing"> </span></span>代替朴素的<span><span class="heti-spacing"> </span>FFN</span>，以此来提高模型的性能。</p>
<div class="arithmatex">\[
FFN_{SwiGLU}(x,W,V,W_2)=(Swish_1(xW)\otimes xV)W_2
\]</div>
<p></p><div align="center"> <img src="https://cdn.hobbitqia.cc/20240609105404.png" width="80%/"/> </div>
</li>
<li>
<p>其中<span class="heti-skip"><span class="heti-spacing"> </span>Swish<span class="heti-spacing"> </span></span>的定义为：<span class="arithmatex">\(Swish(x)=x\cdot sigmoid(x)\)</span></p>
<p></p><div align="center"> <img src="https://cdn.hobbitqia.cc/20240609105424.png" width="100%/"/> </div>
</li>
</ul>
</li>
</ul>
<h2 id="large-language-models-llms">Large language models (LLMs)<a class="headerlink" href="#large-language-models-llms" title="Permanent link">¶</a></h2>
<ul>
<li>
<p><span>LLMs<span class="heti-spacing"> </span></span>表现出一些只有在足够大的模型下才能获得的突现能力。</p>
<p></p><div align="center"> <img src="https://cdn.hobbitqia.cc/20240609105635.png" width="100%/"/> </div>
<p>上面图中可以看到，在<span class="heti-skip"><span class="heti-spacing"> </span>size<span class="heti-spacing"> </span></span>超过<span class="heti-skip"><span class="heti-spacing"> </span><span class="arithmatex">\(10^{22}\)</span><span class="heti-spacing"> </span></span>后，<span>LLMs<span class="heti-spacing"> </span></span>在<span class="heti-skip"><span class="heti-spacing"> </span>Modified arithmetic<span class="heti-spacing"> </span></span>等任务上的准确度显著提升。 </p>
</li>
<li>
<p><strong>GPT-3</strong></p>
<ul>
<li>将<span class="heti-skip"><span class="heti-spacing"> </span>transformer<span class="heti-spacing"> </span></span>扩展为<span class="heti-skip"><span class="heti-spacing"> </span>few-shot learners (in-context learning).<span class="heti-spacing"> </span></span>传统的<span class="heti-skip"><span class="heti-spacing"> </span>NLP pipeline<span class="heti-spacing"> </span></span>是先预训练，随后对下游任务进行微调。而<span class="heti-skip"><span class="heti-spacing"> </span>GPT-3<span class="heti-spacing"> </span></span>可以直接在下游任务上进行学习，不再需要微调。</li>
<li>
<p><span>Scaled-up LLM (175B)<span class="heti-spacing"> </span></span>可以泛化到新的任务，通过<span><span class="heti-spacing"> </span>zero/few-shot:</span></p>
<ul>
<li><span>Zero-shot:<span class="heti-spacing"> </span></span>给定任务描述，回答问题。</li>
<li><span>Few-shot:<span class="heti-spacing"> </span></span>给定<span class="heti-skip"><span class="heti-spacing"> </span>demonstrations<span class="heti-spacing"> </span></span>示范，回答问题。</li>
</ul>
<p></p><div align="center"> <img src="https://cdn.hobbitqia.cc/20240609110211.png" width="95%/"/> </div>
</li>
<li>
<p>我们发现更大的模型可以更有效地利用<span class="heti-skip"><span class="heti-spacing"> </span>few-shot<span class="heti-spacing"> </span></span>的示范。而且给更多的示范，<span>no-prompt<span class="heti-spacing"> </span></span>的精确度也可以赶上<span class="heti-skip"><span class="heti-spacing"> </span>task-prompted<span class="heti-spacing"> </span></span>的精确度。</p>
<p></p><div align="center"> <img src="https://cdn.hobbitqia.cc/20240609110355.png" width="80%/"/> </div>
</li>
<li>
<p>GPT Family:</p>
<ul>
<li>GPT-1 (2018): 117 million</li>
<li>GPT-2 (2019): 1.5B</li>
<li>GPT-3 (2020): 175B</li>
<li>GPT-4 (2023): ???</li>
</ul>
<p></p><div align="center"> <img src="https://cdn.hobbitqia.cc/20240609110433.png" width="80%/"/> </div>
</li>
</ul>
</li>
<li>
<p><strong>OPT</strong></p>
<ul>
<li><span>Open Pre-trained Transformer Language Models (OPT)<span class="heti-spacing"> </span></span>是来自<span class="heti-skip"><span class="heti-spacing"> </span>Meta 2022<span class="heti-spacing"> </span></span>的开源预训练大模型。</li>
<li>模型大小：125M/350M/1.3B/2.7B/6.7B/13B/30B/66B/175B</li>
<li>Decoder-only, Pren-norm(Post-norm for 350M), ReLU in FFN.</li>
<li><span>175B model:<span class="heti-spacing"> </span></span>隐藏层维度<span><span class="heti-spacing"> </span>12288</span>，<span>96<span class="heti-spacing"> </span></span>个注意力头，词典大小<span><span class="heti-spacing"> </span>50k</span>，上下文长度<span><span class="heti-spacing"> </span>2048</span>。</li>
<li>性能与<span class="heti-skip"><span class="heti-spacing"> </span>GPT<span class="heti-spacing"> </span></span>模型很接近。</li>
</ul>
</li>
<li><strong>BLOOM</strong><ul>
<li><span>BLOOM<span class="heti-spacing"> </span></span>是来自<span class="heti-skip"><span class="heti-spacing"> </span>BigScience<span class="heti-spacing"> </span></span>的开源预训练大模型。</li>
<li>模型大小：560M/1.1B/1.7B/3B/7.1B/176B</li>
<li>Decoder-only, Pre-norm, GeLU in FFN, ALiBI</li>
<li><span>176B model:<span class="heti-spacing"> </span></span>隐藏层维度<span><span class="heti-spacing"> </span>14336</span>，<span>112<span class="heti-spacing"> </span></span>个注意力头，词典大小<span><span class="heti-spacing"> </span>250k</span>，上下文长度<span><span class="heti-spacing"> </span>2048</span>。</li>
<li>支持多语言（语料库中包括了<span class="heti-skip"><span class="heti-spacing"> </span>59<span class="heti-spacing"> </span></span>种语言<heti-adjacent class="heti-adjacent-half">）</heti-adjacent>。</li>
</ul>
</li>
<li><strong>LLaMA</strong><ul>
<li><span>Large Language Model Archive (LLaMA)<span class="heti-spacing"> </span></span>是来自<span class="heti-skip"><span class="heti-spacing"> </span>Meta<span class="heti-spacing"> </span></span>的开源预训练大模型。</li>
<li>模型大小：7B/13B/33B/65B</li>
<li>Decoder-decoder, Pre-norm, SwiGLU, RoPE</li>
<li><span>7B model:<span class="heti-spacing"> </span></span>隐藏层维度<span><span class="heti-spacing"> </span>4096</span>，<span>32<span class="heti-spacing"> </span></span>个注意力头，<span>32<span class="heti-spacing"> </span></span>层，词典大小<span><span class="heti-spacing"> </span>32k</span>，上下文长度<span><span class="heti-spacing"> </span>2048</span>。</li>
<li><span>65B model:<span class="heti-spacing"> </span></span>隐藏层维度<span><span class="heti-spacing"> </span>8192</span>，<span>64<span class="heti-spacing"> </span></span>个注意力头，<span>80<span class="heti-spacing"> </span></span>层，词典大小<span><span class="heti-spacing"> </span>32k</span>，上下文长度<span><span class="heti-spacing"> </span>2048</span>。</li>
<li>和之前的开源模型相比，性能更好。</li>
</ul>
</li>
<li><strong>LLaMA 2</strong><ul>
<li>更大的上下文长度（2k-&gt;4k）</li>
<li>更多的训练<span><span class="heti-spacing"> </span>tokens</span>（1T/1.4T-&gt;2T，没有饱和的迹象）</li>
<li>GQA for lager models（70B，<span>64<span class="heti-spacing"> </span></span>个注意力头，<span>8<span class="heti-spacing"> </span></span>个<span class="heti-skip"><span class="heti-spacing"> </span>kv<span class="heti-spacing"> </span></span>头）</li>
<li>也包括了<span><span class="heti-spacing"> </span>Llama-2-chat</span>，一个<span class="heti-skip"><span class="heti-spacing"> </span>instruction-tuned<span class="heti-spacing"> </span></span>的模型。</li>
</ul>
</li>
<li><strong>Falcon</strong><ul>
<li>模型大小：1.3B/7.5B/40B/180B</li>
<li>与<span class="heti-skip"><span class="heti-spacing"> </span>Llama 2<span class="heti-spacing"> </span></span>相比有类似的性能。</li>
</ul>
</li>
<li><strong>Mistral-7B</strong><ul>
<li>更小的模型但是有更好的性能：<span>7B<span class="heti-spacing"> </span></span>模型在<span class="heti-skip"><span class="heti-spacing"> </span>SuperGLUE<span class="heti-spacing"> </span></span>上超过了<span><span class="heti-spacing"> </span>Llama-2-13B, Llama-34B</span>。</li>
<li>隐藏层维度<span><span class="heti-spacing"> </span>4096</span>，<span>32<span class="heti-spacing"> </span></span>个注意力头，<span>8<span class="heti-spacing"> </span></span>个<span class="heti-skip"><span class="heti-spacing"> </span>kv<span class="heti-spacing"> </span></span>头，<span>32<span class="heti-spacing"> </span></span>层，词典大小<span><span class="heti-spacing"> </span>32k</span>，上下文长度<span><span class="heti-spacing"> </span>8k</span>。</li>
<li>有<span class="heti-skip"><span class="heti-spacing"> </span>sliding windows attention (SWA)<span class="heti-spacing"> </span></span>来以较小的代价处理更长的上下文。</li>
</ul>
</li>
</ul>
<div class="admonition note">
<p class="admonition-title">How to scale up? - The Chinchilla Law</p>
<ul>
<li>我们需要同时扩大模型大小和训练用的数据大小，才能实现最好的训练计算和精度之间的平衡。</li>
<li>如果我们考虑推理时计算的<span><span class="heti-spacing"> </span>trade-off</span>，那么这个权衡有所不同。你想要训练一个更小的模型以节省推理成本。</li>
</ul>
<p></p><div align="center"> <img src="https://cdn.hobbitqia.cc/20240609110433.png" width="80%/"/> </div>
<a href="https://cdn.hobbitqia.cc/20240609112431.png">https://cdn.hobbitqia.cc/20240609112431.png</a>
</div>
<h2 id="efficient-inference-algorithms-for-llms">Efficient inference algorithms for LLMs<a class="headerlink" href="#efficient-inference-algorithms-for-llms" title="Permanent link">¶</a></h2>
<h3 id="quantization">Quantization<a class="headerlink" href="#quantization" title="Permanent link">¶</a></h3>
<ul>
<li>
<p><strong>SmoothQuant</strong> (W8A8)</p>
<ul>
<li>
<p>我们希望平滑激活值来降低量化的误差。但是我们发现权重是容易量化的（因为分布均匀<heti-adjacent class="heti-adjacent-half">）</heti-adjacent>，但激活值有很多<span><span class="heti-spacing"> </span>outliers</span>，所以难以量化。但我们发现<span class="heti-skip"><span class="heti-spacing"> </span>outliers<span class="heti-spacing"> </span></span>总是出现在固定的<span><span class="heti-spacing"> </span>channels</span>，因此我们可以把量化的复杂度从激活值转移到权重，这样二者都容易被量化了。</p>
<p></p><div align="center"> <img src="https://cdn.hobbitqia.cc/20240609112938.png" width="100%/"/> </div>
</li>
<li>
<p>平滑的方法就是对于<span class="heti-skip"><span class="heti-spacing"> </span><span class="arithmatex">\(\mathbf{Y=XW}\)</span>,<span class="heti-spacing"> </span></span>将激活值缩小一个比例系数，同时将权重放大一个比例系数。</p>
<p></p><div align="center"> <img src="https://cdn.hobbitqia.cc/20240609114948.png" width="80%/"/> </div>
<ul>
<li>对于<span class="heti-skip"><span class="heti-spacing"> </span><span class="arithmatex">\(\mathbf{Y}=(\mathbf{X} diag(\mathbf{s})^{-1})\cdot (diag(\mathbf{s})\mathbf{W})=\hat{\mathbf{X}}\hat{\mathbf{W}}\)</span>,<span class="heti-spacing"> </span></span>对于权重的缩放可以离线完成，对于激活值的缩放可以折叠到<span class="heti-skip"><span class="heti-spacing"> </span>LayerNorm<span class="heti-spacing"> </span></span>的放射变换的因子中。因此实际上这个操作没有<span><span class="heti-spacing"> </span>runtime overhead</span>。</li>
<li>缩放因子<span class="heti-skip"><span class="heti-spacing"> </span><span class="arithmatex">\(s_j\)</span><span class="heti-spacing"> </span></span>实际上是<span class="heti-skip"><span class="heti-spacing"> </span><span class="arithmatex">\(\mathbf{X}\)</span><span class="heti-spacing"> </span></span>的每一列的最大值除上<span class="heti-skip"><span class="heti-spacing"> </span><span class="arithmatex">\(\mathbf{W}\)</span><span class="heti-spacing"> </span></span>每一行的最大值（即对应输入通道<heti-adjacent class="heti-adjacent-half">）</heti-adjacent>。</li>
</ul>
</li>
<li>
<p>实现上，通过这个技巧我们可以把所有<span class="heti-skip"><span class="heti-spacing"> </span>compute-intensive<span class="heti-spacing"> </span></span>的算子（Linears, BMMs）都量化。</p>
<p></p><div align="center"> <img src="https://cdn.hobbitqia.cc/20240609115504.png" width="65%/"/> </div>
</li>
<li>
<p><span>SmoothQuant<span class="heti-spacing"> </span></span>不需要微调也可以保持精度，而且可以加速推理，也可以减少内存占用。且在<span class="heti-skip"><span class="heti-spacing"> </span>LLaMA<span class="heti-spacing"> </span></span>上测试发现，即使引入了<span><span class="heti-spacing"> </span>SwishGLU, RoPE</span>，<span>SmoothQuant<span class="heti-spacing"> </span></span>也不会影响性能。</p>
</li>
</ul>
</li>
<li>
<p><strong>AWQ</strong> for low-bit weight-only quantization</p>
<ul>
<li><span>W8A8<span class="heti-spacing"> </span></span>对于<span class="heti-skip"><span class="heti-spacing"> </span>batch serving<span class="heti-spacing"> </span></span>来说已经很好了，但是单查询的<span class="heti-skip"><span class="heti-spacing"> </span>LLM<span class="heti-spacing"> </span></span>推理依然是<span><span class="heti-spacing"> </span>memory-bounded</span>，即我们需要<span class="heti-skip"><span class="heti-spacing"> </span>low-bit weight-only quantization<span class="heti-spacing"> </span></span>低位的只关注权重的量化（e.g., W4A16<heti-adjacent class="heti-adjacent-half">）</heti-adjacent>。但如果我们直接使用<span class="heti-skip"><span class="heti-spacing"> </span>W3/W4<span class="heti-spacing"> </span></span>量化，性能会有很大的下降。</li>
<li>
<p>我们观察到，权重并不是同等重要，只有<span class="heti-skip"><span class="heti-spacing"> </span>1%<span class="heti-spacing"> </span></span>的突出权重以<span class="heti-skip"><span class="heti-spacing"> </span>FP16<span class="heti-spacing"> </span></span>的格式存储，可以显著改善性能。问题在于如何选择这<span class="heti-skip"><span class="heti-spacing"> </span>1%<span class="heti-spacing"> </span></span>的权重。</p>
<ul>
<li>这里我们不能基于权重的大小来选择，而是应该基于激活值的分布（Activation-awareness<heti-adjacent class="heti-adjacent-half">）</heti-adjacent>。</li>
<li>
<p>我们可以将激活值最大的<span class="heti-skip"><span class="heti-spacing"> </span>channel<span class="heti-spacing"> </span></span>对应的突出权重<span><span class="heti-spacing"> </span><span class="arithmatex">\(\times s\)</span></span>（而不是用<span class="heti-skip"><span class="heti-spacing"> </span>fp16<span class="heti-spacing"> </span></span>存储<heti-adjacent class="heti-adjacent-half">）</heti-adjacent>，其他权重保持不变。所有权重均是<span><span class="heti-spacing"> </span>int4</span>。即<span><span class="heti-spacing"> </span><span class="arithmatex">\(\mathbf{WX} \rightarrow Q\mathbf{(W\cdot s)(s^{-1}\cdot X)}\)</span></span></p>
<div class="admonition note">
<p class="admonition-title">Protecting salient weights by scaling (no mixed prec.)</p>
<p>下面的分析可以看到，通过对部分<span class="heti-skip"><span class="heti-spacing"> </span>channel<span class="heti-spacing"> </span></span>缩放，我们得以降低误差。
</p><div align="center"> <img src="https://cdn.hobbitqia.cc/20240609151024.png" width="100%/"/> </div>
</div>
</li>
<li>
<p>可以采用<span class="heti-skip"><span class="heti-spacing"> </span>data-driven<span class="heti-spacing"> </span></span>的方法进行快速的<span><span class="heti-spacing"> </span>grid search</span>，得到<span class="heti-skip"><span class="heti-spacing"> </span><span class="arithmatex">\(s\)</span><span class="heti-spacing"> </span></span>的取值。</p>
</li>
</ul>
</li>
</ul>
<div class="admonition example">
<p class="admonition-title">Better PPL under low-bit weight-only quantization</p>
<p><span>PPL<span class="heti-spacing"> </span></span>用来衡量模型质量，越低越好。
</p><div align="center"> <img src="https://cdn.hobbitqia.cc/20240609151325.png" width="80%/"/> </div>
</div>
</li>
</ul>
<h3 id="pruningsparsity">Pruning/Sparsity<a class="headerlink" href="#pruningsparsity" title="Permanent link">¶</a></h3>
<ul>
<li>
<p>Pruning</p>
<ul>
<li><strong>Wanda</strong> 对权重剪枝。思想类似于<span><span class="heti-spacing"> </span>AWQ</span>，即我们剪枝权重时应该考虑激活值的分布。</li>
<li>
<p>这里我们使用<span class="heti-skip"><span class="heti-spacing"> </span><span class="arithmatex">\(|weight|\times \|activation\|\)</span><span class="heti-spacing"> </span></span>作为剪枝的准则。</p>
<div class="admonition example">
<p class="admonition-title">Magnitude vs Wanda</p>
<p><span>Wanda<span class="heti-spacing"> </span></span>始终优于基于<span class="heti-skip"><span class="heti-spacing"> </span>maginitude<span class="heti-spacing"> </span></span>的剪枝。
</p><div align="center"> <img src="https://cdn.hobbitqia.cc/20240609151710.png" width="100%/"/> </div>
</div>
</li>
</ul>
</li>
<li>
<p>Attention Sparsity</p>
<ul>
<li>
<p><strong>SpAtten</strong>：对<span class="heti-skip"><span class="heti-spacing"> </span>token &amp; head<span class="heti-spacing"> </span></span>剪枝。特点在于<span><span class="heti-spacing"> </span>cascade pruning</span>，即我们会在运行中逐渐去掉不重要的<span><span class="heti-spacing"> </span>tokens &amp; heads</span>。    </p>
<p></p><div align="center"> <img src="https://cdn.hobbitqia.cc/20240609152047.png" width="90%/"/> </div>
</li>
<li>
<p><strong>H2O</strong>：对<span class="heti-skip"><span class="heti-spacing"> </span>KV cache<span class="heti-spacing"> </span></span>里的<span class="heti-skip"><span class="heti-spacing"> </span>token<span class="heti-spacing"> </span></span>进行剪枝。</p>
<p></p><div align="center"> <img src="https://cdn.hobbitqia.cc/20240609152136.png" width="80%/"/> </div>
</li>
<li>
<p><strong>DejaVu</strong>：用<span class="heti-skip"><span class="heti-spacing"> </span>feature map<span class="heti-spacing"> </span></span>预测下一层哪些<span class="heti-skip"><span class="heti-spacing"> </span>heads<span class="heti-spacing"> </span></span>可以被修剪。</p>
<p></p><div align="center"> <img src="https://cdn.hobbitqia.cc/20240609173635.png" width="90%/"/> </div>
</li>
<li>
<p><strong>Mixture-of-Experts (MoE)</strong></p>
<ul>
<li>
<p>对于每个输入，不激活所有的网络，而是由<span class="heti-skip"><span class="heti-spacing"> </span>router<span class="heti-spacing"> </span></span>决定哪部分网络应该被激活（expert<heti-adjacent class="heti-adjacent-half">）</heti-adjacent>。</p>
<p></p><div align="center"> <img src="https://cdn.hobbitqia.cc/20240609173739.png" width="100%/"/> </div>
</li>
<li>
<p><span>router<span class="heti-spacing"> </span></span>也可以采用不同的路由算法。</p>
<p></p><div align="center"> <img src="https://cdn.hobbitqia.cc/20240609173755.png" width="75%/"/> </div>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="efficient-inference-systems-for-llms">Efficient inference systems for LLMs<a class="headerlink" href="#efficient-inference-systems-for-llms" title="Permanent link">¶</a></h2>
<h3 id="vllm-and-paged-attention">vLLM and Paged Attention<a class="headerlink" href="#vllm-and-paged-attention" title="Permanent link">¶</a></h3>
<ul>
<li>
<p>分析<span class="heti-skip"><span class="heti-spacing"> </span>KV cache<span class="heti-spacing"> </span></span>的使用：当多用户同时访问时，我们需要预先分配一部分空间用作<span><span class="heti-spacing"> </span>KV cache</span>，但是这样会导致内存的浪费。</p>
<ul>
<li>内部碎片：我们不知道输出序列的长度因而<span><span class="heti-spacing"> </span>over-allocated</span>。</li>
<li>保留区：现在这一步不会用到，但未来可能被使用。</li>
<li>外部碎片：因为不同的序列长度，导致不同内存分配之间会有空隙。</li>
</ul>
<p></p><div align="center"> <img src="https://cdn.hobbitqia.cc/20240609174444.png" width="100%/"/> </div>
</li>
<li>
<p>我们从<span class="heti-skip"><span class="heti-spacing"> </span>OS<span class="heti-spacing"> </span></span>中借鉴了<span class="heti-skip"><span class="heti-spacing"> </span>virtual memory<span class="heti-spacing"> </span></span>虚拟内存和<span class="heti-skip"><span class="heti-spacing"> </span>paging<span class="heti-spacing"> </span></span>分页的思想，允许<span class="heti-skip"><span class="heti-spacing"> </span>KV cache<span class="heti-spacing"> </span></span>不连续存储，而逻辑地址保持连续，通过页表来映射。</p>
<div class="admonition example">
<p class="admonition-title">Example</p>
<p></p><div align="center"> <img src="https://cdn.hobbitqia.cc/20240609174624.png" width="100%/"/> </div>
</div>
</li>
<li>
<p><span>Dynamic block mapping enables prompt sharing in parallel sampling.<span class="heti-spacing"> </span></span>即我们可以喂一个<span><span class="heti-spacing"> </span>prompt</span>，随后由多个进程共享，生成多个不同的输出。</p>
</li>
</ul>
<h3 id="streamingllm">StreamingLLM<a class="headerlink" href="#streamingllm" title="Permanent link">¶</a></h3>
<ul>
<li>在<span class="heti-skip"><span class="heti-spacing"> </span>streaming application<span class="heti-spacing"> </span></span>流应用上部署<span class="heti-skip"><span class="heti-spacing"> </span>LLM<span class="heti-spacing"> </span></span>是有挑战的，因为需要消耗大量内存（Out of Memory<heti-adjacent class="heti-adjacent-half">）</heti-adjacent>，而且流行的<span class="heti-skip"><span class="heti-spacing"> </span>LLM<span class="heti-spacing"> </span></span>很难泛化到更长的文本序列（Model Performance Breaks<heti-adjacent class="heti-adjacent-half">）</heti-adjacent>。</li>
<li>一个自然的方法：使用<span><span class="heti-spacing"> </span>window attention</span>，即我们只计算最近邻（窗口范围内）的<span class="heti-skip"><span class="heti-spacing"> </span>Key-Value<span class="heti-spacing"> </span></span>的<span><span class="heti-spacing"> </span>attention</span>。<ul>
<li>问题是当序列长度超过<span class="heti-skip"><span class="heti-spacing"> </span>cache<span class="heti-spacing"> </span></span>大小时，<span>intial token<span class="heti-spacing"> </span></span>起初的信息会被踢出<span><span class="heti-spacing"> </span>window</span>，从而导致性能的显著下降。</li>
</ul>
</li>
<li><strong>Observation</strong><span>:<span class="heti-spacing"> </span></span>最初的<span class="heti-skip"><span class="heti-spacing"> </span>token<span class="heti-spacing"> </span></span>有很大的<span><span class="heti-spacing"> </span>attention scores</span>，尽管这个<span class="heti-skip"><span class="heti-spacing"> </span>token<span class="heti-spacing"> </span></span>在语义上并不重要。<ul>
<li>原因在于，<span>Softmax<span class="heti-spacing"> </span></span>函数中，我们需要让<span class="heti-skip"><span class="heti-spacing"> </span>attention scores<span class="heti-spacing"> </span></span>和为<span><span class="heti-spacing"> </span>1</span>。因此第<span class="heti-skip"><span class="heti-spacing"> </span>1<span class="heti-spacing"> </span></span>个<span class="heti-skip"><span class="heti-spacing"> </span>token<span class="heti-spacing"> </span></span>的优势在于他对于后面<span class="heti-skip"><span class="heti-spacing"> </span>token<span class="heti-spacing"> </span></span>的可见性，这源于自回归语言模型<heti-adjacent class="heti-adjacent-half">。</heti-adjacent>（Attention Sinks）</li>
<li>经过实验可以发现，<span>intial tokens<span class="heti-spacing"> </span></span>重要是源于他的<span class="heti-skip"><span class="heti-spacing"> </span>postion<span class="heti-spacing"> </span></span>而非<span><span class="heti-spacing"> </span>semantics</span>。</li>
</ul>
</li>
<li><strong>StreamingLLM</strong><ul>
<li><strong>Objective</strong>：让<span class="heti-skip"><span class="heti-spacing"> </span>LLM<span class="heti-spacing"> </span></span>能通过有限的<span class="heti-skip"><span class="heti-spacing"> </span>attention windows<span class="heti-spacing"> </span></span>训练，从而能在不额外训练的情况下解决无限文本长度的问题。</li>
<li><strong>Idea</strong>：保存<span class="heti-skip"><span class="heti-spacing"> </span>attention sink tokens<span class="heti-spacing"> </span></span>的<span><span class="heti-spacing"> </span>KV</span>，和<span class="heti-skip"><span class="heti-spacing"> </span>sliding windows'KV<span class="heti-spacing"> </span></span>一起计算来让模型的行为稳定。</li>
<li>在使用位置编码时，我们使用在<span class="heti-skip"><span class="heti-spacing"> </span>cache<span class="heti-spacing"> </span></span>里的位置而不是使用在原始文本中的位置。</li>
<li>同时实现<span class="heti-skip"><span class="heti-spacing"> </span>StreamingLLM<span class="heti-spacing"> </span></span>和<span class="heti-skip"><span class="heti-spacing"> </span>Paged Attention<span class="heti-spacing"> </span></span>时，我们只需要<span class="heti-skip"><span class="heti-spacing"> </span>pin<span class="heti-spacing"> </span></span>住<span><span class="heti-spacing"> </span>intial tokens</span>，保证他们不会被踢出即可。</li>
<li>实验里表明<span class="heti-skip"><span class="heti-spacing"> </span>4 attention sinks<span class="heti-spacing"> </span></span>足够解决问题，同时我们可以训练一个只需要<span class="heti-skip"><span class="heti-spacing"> </span>1<span class="heti-spacing"> </span></span>个<span class="heti-skip"><span class="heti-spacing"> </span>sink<span class="heti-spacing"> </span></span>的<span><span class="heti-spacing"> </span>LLM</span>。方法是引进一个额外的可学习的<span class="heti-skip"><span class="heti-spacing"> </span>token<span class="heti-spacing"> </span></span>在最开始。</li>
</ul>
</li>
</ul>
<h3 id="flashattention">FlashAttention<a class="headerlink" href="#flashattention" title="Permanent link">¶</a></h3>
<ul>
<li>
<p><strong>FlashAttention</strong> 使用<span class="heti-skip"><span class="heti-spacing"> </span>tiling<span class="heti-spacing"> </span></span>来阻止<span class="heti-skip"><span class="heti-spacing"> </span><span class="arithmatex">\(N\times N\)</span> attention<span class="heti-spacing"> </span></span>矩阵的<span><span class="heti-spacing"> </span>materialization</span>，因此避免了使用缓慢的<span><span class="heti-spacing"> </span>HBM</span>，还使用了<span class="heti-skip"><span class="heti-spacing"> </span>kernel fusion<span class="heti-spacing"> </span></span>的技巧。</p>
<p></p><div align="center"> <img src="https://cdn.hobbitqia.cc/20240609202947.png" width="100%/"/> </div>
</li>
</ul>
<h3 id="speculative-decoding">Speculative Decoding<a class="headerlink" href="#speculative-decoding" title="Permanent link">¶</a></h3>
<ul>
<li><strong>投机译码</strong>，用来加速<span class="heti-skip"><span class="heti-spacing"> </span>memory-bounded<span class="heti-spacing"> </span></span>的生成。<span>LLM<span class="heti-spacing"> </span></span>的<span class="heti-skip"><span class="heti-spacing"> </span>decoding<span class="heti-spacing"> </span></span>阶段都是<span><span class="heti-spacing"> </span>token by token</span>，即一个一个地输出，这会导致内存受限（因为<span class="heti-skip"><span class="heti-spacing"> </span>batch size<span class="heti-spacing"> </span></span>很小）</li>
<li>投机译码中，我们有两个模型：<ul>
<li><span>Draft model<span class="heti-spacing"> </span></span>是一个比较小的<span><span class="heti-spacing"> </span>LLM</span>（如<span><span class="heti-spacing"> </span>7B</span>）</li>
<li><span>Target model<span class="heti-spacing"> </span></span>是一个比较大的<span><span class="heti-spacing"> </span>LLM</span>（如<span><span class="heti-spacing"> </span>175B</span><heti-adjacent class="heti-adjacent-half">）</heti-adjacent>，即我们希望加速的模型。</li>
</ul>
</li>
<li>
<p>具体流程：<span>draft model<span class="heti-spacing"> </span></span>自回归地生成<span class="heti-skip"><span class="heti-spacing"> </span><span class="arithmatex">\(K\)</span><span class="heti-spacing"> </span></span>个<span><span class="heti-spacing"> </span>tokens</span>（batch size <span class="arithmatex">\(K\)</span><heti-adjacent class="heti-adjacent-half">）</heti-adjacent>，将这<span class="heti-skip"><span class="heti-spacing"> </span><span class="arithmatex">\(K\)</span><span class="heti-spacing"> </span></span>个<span class="heti-skip"><span class="heti-spacing"> </span>tokens<span class="heti-spacing"> </span></span>并行地送入目标模型，并得到预测的概率。最后决定接受还是拒绝这<span class="heti-skip"><span class="heti-spacing"> </span><span class="arithmatex">\(K\)</span><span class="heti-spacing"> </span></span>个<span><span class="heti-spacing"> </span>tokens</span>。</p>
<p></p><div align="center"> <img src="https://cdn.hobbitqia.cc/20240609203623.png" width="75%/"/> </div>
</li>
<li>
<p>因为多个<span class="heti-skip"><span class="heti-spacing"> </span>tokens<span class="heti-spacing"> </span></span>是并行送入<span class="heti-skip"><span class="heti-spacing"> </span>target model<span class="heti-spacing"> </span></span>的，所以提高了内存的瓶颈。</p>
</li>
</ul>
<h2 id="efficient-fine-tuning-for-llms">Efficient fine-tuning for LLMs<a class="headerlink" href="#efficient-fine-tuning-for-llms" title="Permanent link">¶</a></h2>
<ul>
<li>
<p><strong>LoRA</strong>: Low-rank adaptation </p>
<ul>
<li>
<p>不更新整个模型权重，而是只更新<span class="heti-skip"><span class="heti-spacing"> </span>low-rank<span class="heti-spacing"> </span></span>的小部分。</p>
<p></p><div align="center"> <img src="https://cdn.hobbitqia.cc/20240609204150.png" width="45%/"/> </div>
</li>
<li>
<p>好处是可以加速微调（因为跳过了梯度计算<heti-adjacent class="heti-adjacent-half">）</heti-adjacent>，节约了微调内存（减少了优化器状态<heti-adjacent class="heti-adjacent-half">）</heti-adjacent>，阻止了灾难性的遗忘，低秩权重是可以融合的。</p>
</li>
</ul>
</li>
<li>
<p><strong>QLoRA</strong>: LoRA with quantized base model weights</p>
<ul>
<li>
<p>使用了<span><span class="heti-spacing"> </span>NormalFloat (NF4)</span>，进行了两次量化（对<span class="heti-skip"><span class="heti-spacing"> </span>scaling factor<span class="heti-spacing"> </span></span>也进行了量化）来进一步降低基础模型的大小，支持带有<span class="heti-skip"><span class="heti-spacing"> </span>CPU Offload<span class="heti-spacing"> </span></span>的分页优化器。</p>
<p></p><div align="center"> <img src="https://cdn.hobbitqia.cc/20240609204838.png" width="75%/"/> </div>
</li>
</ul>
</li>
<li>
<p><strong>Adapter</strong></p>
<ul>
<li>
<p>smaller adapter for transfer learning, cannot be fused.</p>
<p></p><div align="center"> <img src="https://cdn.hobbitqia.cc/20240609204925.png" width="90%/"/> </div>
</li>
</ul>
</li>
<li>
<p><strong>Prompt Tuning</strong>: From discrete prompt to continuous prompt</p>
<ul>
<li>我们可以训练<span><span class="heti-spacing"> </span>continuous prompt</span>，附加到每个任务的输入中。</li>
<li>
<p>我们还可以把不同的可学习的<span class="heti-skip"><span class="heti-spacing"> </span>prompt<span class="heti-spacing"> </span></span>混合在一个<span class="heti-skip"><span class="heti-spacing"> </span>batch<span class="heti-spacing"> </span></span>中。</p>
<p></p><div align="center"> <img src="https://cdn.hobbitqia.cc/20240609205133.png" width="85%/"/> </div>
</li>
</ul>
</li>
</ul>
<aside class="md-source-file">
<span class="md-source-file__fact">
<span class="md-icon" title="最后更新">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M21 13.1c-.1 0-.3.1-.4.2l-1 1 2.1 2.1 1-1c.2-.2.2-.6 0-.8l-1.3-1.3c-.1-.1-.2-.2-.4-.2m-1.9 1.8-6.1 6V23h2.1l6.1-6.1zM12.5 7v5.2l4 2.4-1 1L11 13V7zM11 21.9c-5.1-.5-9-4.8-9-9.9C2 6.5 6.5 2 12 2c5.3 0 9.6 4.1 10 9.3-.3-.1-.6-.2-1-.2s-.7.1-1 .2C19.6 7.2 16.2 4 12 4c-4.4 0-8 3.6-8 8 0 4.1 3.1 7.5 7.1 7.9l-.1.2z"></path></svg>
</span>
<span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-datetime" title="2024年6月9日 21:14:33 CST">2024年6月9日 21:14:33</span>
</span>
<span class="md-source-file__fact">
<span class="md-icon" title="创建日期">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M14.47 15.08 11 13V7h1.5v5.25l3.08 1.83c-.41.28-.79.62-1.11 1m-1.39 4.84c-.36.05-.71.08-1.08.08-4.42 0-8-3.58-8-8s3.58-8 8-8 8 3.58 8 8c0 .37-.03.72-.08 1.08.69.1 1.33.32 1.92.64.1-.56.16-1.13.16-1.72 0-5.5-4.5-10-10-10S2 6.5 2 12s4.47 10 10 10c.59 0 1.16-.06 1.72-.16-.32-.59-.54-1.23-.64-1.92M18 15v3h-3v2h3v3h2v-3h3v-2h-3v-3z"></path></svg>
</span>
<span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-datetime" title="2024年6月9日 21:14:33 CST">2024年6月9日 21:14:33</span>
</span>
</aside>
<link href="/css/counter.css" rel="stylesheet"/>
<!-- Giscus -->
<h2 id="__comments">评论</h2>
<!-- 这里改成你的Giscus代码 -->
<script async="" crossorigin="anonymous" data-category="General" data-category-id="DIC_kwDOHtZjDs4CQZ7Z" data-emit-metadata="0" data-input-position="top" data-lang="zh-CN" data-mapping="pathname" data-reactions-enabled="1" data-repo="HobbitQia/notebook" data-repo-id="R_kgDOHtZjDg" data-strict="0" data-theme="light" src="https://giscus.app/client.js">
</script>
<!-- Reload on palette change -->
<script>
    var palette = __md_get("__palette")
    if (palette && typeof palette.color === "object")
        if (palette.color.scheme === "slate") {
            var giscus = document.querySelector("script[src*=giscus]")
            giscus.setAttribute("data-theme", "dark")
        }

    /* Register event handlers after documented loaded */
    document.addEventListener("DOMContentLoaded", function () {
        var ref = document.querySelector("[data-md-component=palette]")
        ref.addEventListener("change", function () {
            var palette = __md_get("__palette")
            if (palette && typeof palette.color === "object") {
                var theme = palette.color.scheme === "slate" ? "dark" : "light"

                /* Instruct Giscus to change theme */
                var frame = document.querySelector(".giscus-frame")
                frame.contentWindow.postMessage(
                    { giscus: { setConfig: { theme } } },
                    "https://giscus.app"
                )
            }
        })
    })
</script>
</article>
</div>
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
</div>
<button class="md-top md-icon" data-md-component="top" hidden="" type="button">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"></path></svg>
  回到页面顶部
</button>
</main>
<footer class="md-footer">
<div class="md-footer-meta md-typeset">
<div class="md-footer-meta__inner md-grid">
<div class="md-copyright">
<div class="md-copyright__highlight">
      Copyright © 2022 <a href="https://github.com/HobbitQia" rel="noopener" target="_blank">HobbitQia</a>
</div>
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" rel="noopener" target="_blank">
      Material for MkDocs
    </a>
</div>
<div class="md-social">
<a class="md-social__link" href="https://github.com/HobbitQia/" rel="noopener" target="_blank" title="github.com">
<svg viewbox="0 0 512 512" xmlns="http://www.w3.org/2000/svg"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"></path></svg>
</a>
</div>
</div>
</div>
</footer>
</div>
<div class="md-dialog" data-md-component="dialog">
<div class="md-dialog__inner md-typeset"></div>
</div>
<script id="__config" type="application/json">{"base": "../..", "features": ["content.code.annotate", "navigation.tracking", "navigation.tabs", "navigation.indexes", "navigation.top"], "search": "../../assets/javascripts/workers/search.973d3a69.min.js", "tags": null, "translations": {"clipboard.copied": "\u5df2\u590d\u5236", "clipboard.copy": "\u590d\u5236", "search.result.more.one": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.more.other": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 # \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.none": "\u6ca1\u6709\u627e\u5230\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.one": "\u627e\u5230 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.other": "# \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.placeholder": "\u952e\u5165\u4ee5\u5f00\u59cb\u641c\u7d22", "search.result.term.missing": "\u7f3a\u5c11", "select.version": "\u9009\u62e9\u5f53\u524d\u7248\u672c"}, "version": null}</script>
<script src="../../assets/javascripts/bundle.f55a23d4.min.js"></script>
<script src="../../js/baidu-tongji.js"></script>
<script src="https://gcore.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.js"></script>
<script src="../../js/katex.js"></script>
<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>
<script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</body>
</html>